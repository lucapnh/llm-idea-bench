{
    "query": "Ensemble Kalman Filter extensions",
    "result": {
        "1": "Kalman Filter and its Modern Extensions for the Continuous-time Nonlinear Filtering Problem. A. Taghvaei, J. Wiljes, P. Mehta, S. Reich. arXiv.org, 2017.\nNumber of citations: 46\nAbstract: This paper is concerned with the filtering problem in continuous-time. Three algorithmic solution approaches for this problem are reviewed: (i) the classical Kalman-Bucy filter which provides an exact solution for the linear Gaussian problem, (ii) the ensemble Kalman-Bucy filter (EnKBF) which is an approximate filter and represents an extension of the Kalman-Bucy filter to nonlinear problems, and (iii) the feedback particle filter (FPF) which represents an extension of the EnKBF and furthermore provides for an consistent solution in the general nonlinear, non-Gaussian case. The common feature of the three algorithms is the gain times error formula to implement the update step (to account for conditioning due to the observations) in the filter. In contrast to the commonly used sequential Monte Carlo methods, the EnKBF and FPF avoid the resampling of the particles in the importance sampling update step. Moreover, the feedback control structure provides for error correction potentially leading to smaller simulation variance and improved stability properties. The paper also discusses the issue of non-uniqueness of the filter update formula and formulates a novel approximation algorithm based on ideas from optimal transport and coupling of measures. Performance of this and other algorithms is illustrated for a numerical example.",
        "2": "A Multifidelity Ensemble Kalman Filter with Reduced Order Control Variates. A. Popov, Changhong Mou, T. Iliescu, Adrian Sandu. SIAM Journal on Scientific Computing, 2020.\nNumber of citations: 42\nAbstract: This work develops a new multifidelity ensemble Kalman filter (MFEnKF) algorithm based on linear control variate framework. The approach allows for rigorous multifidelity extensions of the EnKF, where the uncertainty in coarser fidelities in the hierarchy of models represent control variates for the uncertainty in finer fidelities. Small ensembles of high fidelity model runs are complemented by larger ensembles of cheaper, lower fidelity runs, to obtain much improved analyses at only small additional computational costs. We investigate the use of reduced order models as coarse fidelity control variates in the MFEnKF, and provide analyses to quantify the improvements over the traditional ensemble Kalman filters. We apply these ideas to perform data assimilation with a quasi-geostrophic test problem, using direct numerical simulation and a corresponding POD-Galerkin reduced order model. Numerical results show that the two-fidelity MFEnKF provides better analyses than existing EnKF algorithms at comparable or reduced computational costs.",
        "3": "Ensemble MCMC: Accelerating Pseudo-Marginal MCMC for State Space Models using the Ensemble Kalman Filter. C. Drovandi, R. Everitt, A. Golightly, D. Prangle. Bayesian Analysis, 2019.\nNumber of citations: 14\nAbstract: Particle Markov chain Monte Carlo (pMCMC) is now a popular method for performing Bayesian statistical inference on challenging state space models (SSMs) with unknown static parameters. It uses a particle filter (PF) at each iteration of an MCMC algorithm to unbiasedly estimate the likelihood for a given static parameter value. However, pMCMC can be computationally intensive when a large number of particles in the PF is required, such as when the data is highly informative, the model is misspecified and/or the time series is long. In this paper we exploit the ensemble Kalman filter (EnKF) developed in the data assimilation literature to speed up pMCMC. We replace the unbiased PF likelihood with the biased EnKF likelihood estimate within MCMC to sample over the space of the static parameter. On a wide class of different non-linear SSM models, we demonstrate that our new ensemble MCMC (eMCMC) method can significantly reduce the computational cost whilst maintaining reasonable accuracy. We also propose several extensions of the vanilla eMCMC algorithm to further improve computational efficiency. Computer code to implement our methods on all the examples can be downloaded from this https URL.",
        "4": "A comparison of nonlinear extensions to the ensemble Kalman filter. Ian G. Grooms. Computational Geosciences, 2021.\nNumber of citations: 12\nAbstract: Ensemble Kalman filters are based on a Gaussian assumption, which can limit their performance in some non-Gaussian settings. This paper reviews two nonlinear, non-Gaussian extensions of the Ensemble Kalman Filter: Gaussian anamorphosis (GA) methods and two-step updates, of which the rank histogram filter (RHF) is a prototypical example. GA-EnKF methods apply univariate transforms to the state and observation variables to make their distribution more Gaussian before applying an EnKF. The two-step methods use a scalar Bayesian update for the first step, followed by linear regression for the second step. The connection of the two-step framework to the full Bayesian problem is made, which opens the door to more advanced two-step methods in the full Bayesian setting. A new method for the first part of the two-step framework is proposed, with a similar form to the RHF but a different motivation, called the \u2018improved RHF\u2019 (iRHF). A suite of experiments with the Lorenz-\u201896 model demonstrate situations where the GA-EnKF methods are similar to EnKF, and where they outperform EnKF. The experiments also strongly support the accuracy of the RHF and iRHF filters for nonlinear and non-Gaussian observations; these methods uniformly beat the EnKF and GA-EnKF methods in the experiments reported here. The new iRHF method is only more accurate than RHF at small ensemble sizes in the experiments reported here.",
        "5": "Filter comparison for estimation on discretized PDEs modeling traffic: Ensemble Kalman Filter and minimax filter. Toru Seo, T. Tchrakian, S. Zhuk, A. Bayen. IEEE Conference on Decision and Control, 2016.\nNumber of citations: 12\nAbstract: None",
        "6": "Second Order Extended Ensemble Filter for Non-linear Filtering. Kevin Midenyo, David Angwenyi, Duncan Oganga. African Journal of Empirical Research, 2024.\nNumber of citations: 1\nAbstract: Whenever the state of a system must be estimated from noisy information, a state estimator is employed to fuse the data with the model to produce an accurate estimate of the state. When the system dynamics and observation models are linear, the Kalman Filter which is optimal, is used. However, in most applications of interest the system dynamics and observations equations are not- linear and suitable extensions of the Kalman Filter have been developed; for example, the Extended Kalman Filter(EKF). The Extended Kalman Filter is based on linearization by the Taylor series expansion about the mean of the state. This filtering process is however computationally expensive especially in high dimensional data. The cause for this is the high cost of integrating the equation of evolution of covariances. Due to this complexity in integration, new methods were sought known as the particle filters. It replaces linearization of non-linearities with Monte Carlo methods. The particle filter formed a basis for Ensemble Kalman Filter (EnKF) an extension of Kalman filter to non-linear filtering. The EnKF reduced the computational cost but its innovation process does not capture information sufficiently hence there is need to improve its performance. This study has developed a new filter, Second order Extended Ensemble Filter (SoEEF).We derived it from stochastic state models by expansion of expected values to the second order by use of Taylor series together with Monte Carlo method and Matlab. We used Lorenz 63 system of ordinary equations and differential Matlab to test the performance of the new filter. Then we compared its performance with four other filters like Bootstrap Particle Filter (BPF), First order Kalman Bucy Filter (FoEKBF),Second order Kalman Bucy Filter (SoKBF) and First order Extended Ensemble Filter (FoEEF). SoEEKF performs much better than the other four filters.",
        "7": "Surrogate Tree and Model Forest Extensions to the Multi\ufb01delity Ensemble Kalman Filter. A. Popov, Adrian Sandu. , 2021.\nNumber of citations: 0\nAbstract: None",
        "8": "Extending ensemble Kalman filter algorithms to assimilate observations with an unknown time offset. Elia Gorokhovsky, Jeffrey L. Anderson. Nonlinear Processes in Geophysics, 2023.\nNumber of citations: 0\nAbstract: Abstract. Data assimilation (DA), the statistical combination of\ncomputer models with measurements, is applied in a variety of scientific\nfields involving forecasting of dynamical systems, most prominently in\natmospheric and ocean sciences. The existence of misreported or unknown\nobservation times (time error) poses a unique and interesting problem for\nDA. Mapping observations to incorrect times causes bias in the prior state\nand affects assimilation. Algorithms that can improve the performance of\nensemble Kalman filter DA in the presence of observing time error are\ndescribed. Algorithms that can estimate the distribution of time error are\nalso developed. These algorithms are then combined to produce extensions to\nensemble Kalman filters that can both estimate and correct for observation\ntime errors. A low-order dynamical system is used to evaluate the\nperformance of these methods for a range of magnitudes of observation time\nerror. The most successful algorithms must explicitly account for the\nnonlinearity in the evolution of the prediction model.",
        "9": "A competitive baseline for deep learning enhanced data assimilation using conditional Gaussian ensemble Kalman filtering. Zachariah Malik, R. Maulik. Computer Methods in Applied Mechanics and Engineering, 2024.\nNumber of citations: 0\nAbstract: Ensemble Kalman Filtering (EnKF) is a popular technique for data assimilation, with far ranging applications. However, the vanilla EnKF framework is not well-defined when perturbations are nonlinear. We study two non-linear extensions of the vanilla EnKF - dubbed the conditional-Gaussian EnKF (CG-EnKF) and the normal score EnKF (NS-EnKF) - which sidestep assumptions of linearity by constructing the Kalman gain matrix with the `conditional Gaussian' update formula in place of the traditional one. We then compare these models against a state-of-the-art deep learning based particle filter called the score filter (SF). This model uses an expensive score diffusion model for estimating densities and also requires a strong assumption on the perturbation operator for validity. In our comparison, we find that CG-EnKF and NS-EnKF dramatically outperform SF for a canonical problem in high-dimensional multiscale data assimilation given by the Lorenz-96 system. Our analysis also demonstrates that the CG-EnKF and NS-EnKF can handle highly non-Gaussian additive noise perturbations, with the latter typically outperforming the former."
    }
}