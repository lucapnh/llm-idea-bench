{
    "query": "language models reasoning acting decision-making",
    "result": {
        "1": "Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models. Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman, Haohan Wang, Yu-Xiong Wang. International Conference on Machine Learning, 2023.\nNumber of citations: 248\nAbstract: While language models (LMs) have shown potential across a range of decision-making tasks, their reliance on simple acting processes limits their broad deployment as autonomous agents. In this paper, we introduce Language Agent Tree Search (LATS) -- the first general framework that synergizes the capabilities of LMs in reasoning, acting, and planning. By leveraging the in-context learning ability of LMs, we integrate Monte Carlo Tree Search into LATS to enable LMs as agents, along with LM-powered value functions and self-reflections for proficient exploration and enhanced decision-making. A key feature of our approach is the incorporation of an environment for external feedback, which offers a more deliberate and adaptive problem-solving mechanism that surpasses the constraints of existing techniques. Our experimental evaluation across diverse domains, including programming, interactive question-answering (QA), web navigation, and math, validates the effectiveness and generality of LATS in decision-making while maintaining competitive or improved reasoning performance. Notably, LATS achieves state-of-the-art pass@1 accuracy (92.7%) for programming on HumanEval with GPT-4 and demonstrates gradient-free performance (average score of 75.9) comparable to gradient-based fine-tuning for web navigation on WebShop with GPT-3.5. Code can be found at https://github.com/lapisrocks/LanguageAgentTreeSearch",
        "2": "Drive as You Speak: Enabling Human-Like Interaction with Large Language Models in Autonomous Vehicles. Can Cui, Yunsheng Ma, Xu Cao, Wenqian Ye, Ziran Wang. 2024 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW), 2023.\nNumber of citations: 127\nAbstract: The future of autonomous vehicles lies in the convergence of human-centric design and advanced AI capabilities. Autonomous vehicles of the future will not only transport passengers but also interact and adapt to their desires, making the journey comfortable, efficient, and pleasant. In this paper, we present a novel framework that leverages Large Language Models (LLMs) to enhance autonomous vehicles' decision-making processes. By integrating LLMs' natural language capabilities and contextual understanding, specialized tools usage, synergizing reasoning, and acting with various modules on autonomous vehicles, this framework aims to seamlessly integrate the advanced language and reasoning capabilities of LLMs into autonomous vehicles. The proposed framework holds the potential to revolutionize the way autonomous vehicles operate, offering personalized assistance, continuous learning, and transparent decision-making, ultimately contributing to safer and more efficient autonomous driving technologies.",
        "3": "Asking Before Acting: Gather Information in Embodied Decision Making with Language Models. Xiaoyu Chen, Shenao Zhang, Pushi Zhang, Li Zhao, Jianyu Chen. , 2023.\nNumber of citations: 10\nAbstract: With strong capabilities of reasoning and a broad understanding of the world, Large Language Models (LLMs) have demonstrated immense potential in building versatile embodied decision-making agents capable of executing a wide array of tasks. Nevertheless, when deployed in unfamiliar environments, we show that LLM agents encounter challenges in efficiently gathering essential information, leading to suboptimal performance. Conversely, human individuals often seek additional information from their peers prior to taking action, harnessing external knowledge to avoid unnecessary trial and error. Drawing inspiration from this behavior, we propose \\textit{Asking Before Acting} (ABA), a method that empowers the agent to proactively inquire with external sources for pertinent information using natural language during their interactions within the environment. In this way, the agent is able to enhance its efficiency and performance by circumventing potentially laborious steps and combating the difficulties associated with exploration in unfamiliar environments and vagueness of the instructions. We conduct extensive experiments involving a spectrum of environments including text-based household everyday tasks, robot arm manipulation tasks, and real world open domain image based embodied tasks. The experiments involve various models from Vicuna to GPT-4. The results demonstrate that, even with modest prompts modifications, ABA exhibits substantial advantages on both performance and efficiency over baseline LLM agents. Further finetuning ABA with reformulated metadata (ABA-FT) faciliates learning the rationale for asking and allows for additional enhancements especially in tasks that baselines struggle to solve.",
        "4": "Adaptive Reasoning and Acting in Medical Language Agents. Abhishek Dutta, Yen-Che Hsiao. arXiv.org, 2024.\nNumber of citations: 5\nAbstract: This paper presents an innovative large language model (LLM) agent framework for enhancing diagnostic accuracy in simulated clinical environments using the AgentClinic benchmark. The proposed automatic correction enables doctor agents to iteratively refine their reasoning and actions following incorrect diagnoses, fostering improved decision-making over time. Experiments show that the implementation of the adaptive LLM-based doctor agents achieve correct diagnoses through dynamic interactions with simulated patients. The evaluations highlight the capacity of autonomous agents to adapt and improve in complex medical scenarios. Future enhancements will focus on refining the algorithm and expanding its applicability across a wider range of tasks and different large language models.",
        "5": "ReSpAct: Harmonizing Reasoning, Speaking, and Acting Towards Building Large Language Model-Based Conversational AI Agents. Vardhan Dongre, Xiaocheng Yang, Emre Can Acikgoz, Suvodip Dey, Gokhan Tur, Dilek Hakkani-Tur. arXiv.org, 2024.\nNumber of citations: 5\nAbstract: Large language model (LLM)-based agents are increasingly employed to interact with external environments (e.g., games, APIs, world models) to solve user-provided tasks. However, current frameworks often lack the ability to collaborate effectively with users in fully conversational settings. Conversations are essential for aligning on task details, achieving user-defined goals, and satisfying preferences. While existing agents address ambiguity through clarification questions, they underutilize the broader potential of an LLM's conversational capabilities. In this work, we introduce ReSpAct, an LLM-based agent designed to seamlessly integrate reasoning, decision-making, and dynamic dialogue for task-solving. Expanding on reasoning-first approaches like ReAct, ReSpAct employs active, free-flowing dialogues to interpret instructions, clarify goals, provide status updates, resolve subtask failures, and refine plans based on user inputs without any explicit dialogue schema. By alternating between task-solving actions and interactive conversations, ReSpAct demonstrates improved performance across diverse environments. We evaluate ReSpAct in user-interactive settings, including task-oriented dialogue systems (MultiWOZ) and decision-making tasks (ALFWorld, WebShop). ReSpAct outperforms ReAct with absolute success rate improvements of 6% and 4% in ALFWorld and WebShop, respectively, and achieves a 5.5% gain in Inform and a 3% gain in Success scores in MultiWOZ. These results highlight the value of integrating dynamic user-agent collaboration for more effective task resolution.",
        "6": "Towards Autonomous Agents: Adaptive-planning, Reasoning, and Acting in Language Models. Yen-Che Hsiao, Abhishek Dutta. arXiv.org, 2024.\nNumber of citations: 2\nAbstract: We propose a novel in-context learning algorithm for building autonomous decision-making language agents. The language agent continuously attempts to solve the same task by self-correcting each time the task fails. Our selected language agent demonstrates the ability to solve tasks in a text-based game environment. Our results show that the gemma-2-9b-it language model, using our proposed method, can successfully complete two of six tasks that failed in the first attempt. This highlights the effectiveness of our approach in enhancing the problem-solving capabilities of a single language model through self-correction, paving the way for more advanced autonomous agents. The code is publicly available at https://github.com/YenCheHsiao/AutonomousLLMAgentwithAdaptingPlanning.",
        "7": "Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting. Wei Chen, Jiahao Zhang, Haipeng Zhu, Boyan Xu, Zhifeng Hao, Keli Zhang, Junjian Ye, Ruichu Cai. arXiv.org, 2025.\nNumber of citations: 1\nAbstract: Large language models (LLMs) have shown great potential in decision-making due to the vast amount of knowledge stored within the models. However, these pre-trained models are prone to lack reasoning abilities and are difficult to adapt to new environments, further hindering their application to complex real-world tasks. To address these challenges, inspired by the human cognitive process, we propose Causal-aware LLMs, which integrate the structural causal model (SCM) into the decision-making process to model, update, and utilize structured knowledge of the environment in a ``learning-adapting-acting\"paradigm. Specifically, in the learning stage, we first utilize an LLM to extract the environment-specific causal entities and their causal relations to initialize a structured causal model of the environment. Subsequently,in the adapting stage, we update the structured causal model through external feedback about the environment, via an idea of causal intervention. Finally, in the acting stage, Causal-aware LLMs exploit structured causal knowledge for more efficient policy-making through the reinforcement learning agent. The above processes are performed iteratively to learn causal knowledge, ultimately enabling the causal-aware LLMs to achieve a more accurate understanding of the environment and make more efficient decisions. Experimental results across 22 diverse tasks within the open-world game ``Crafter\"validate the effectiveness of our proposed method.",
        "8": "Decision-Making in Agentic Frameworks for Large Language Model Applications. Syed Arham Akheel. Journal of Engineering and Applied Sciences Technology, 2024.\nNumber of citations: 0\nAbstract: Recent advances in agentic frameworks, powered by large language models (LLMs), have led to significant developments in decision-making systems\nthat integrate reasoning and acting. This paper provides a comparative analysis of various decision-making models within agentic frameworks, focusing\non reasoning strategies, memory augmentation, and situational awareness. Specifically, I analyze models such as ReAct, memory augmented systems\nlike JARVIS-1, and cognitive language architectures like CoALA. I demonstrate that incorporating memory and situational awareness significantly\nenhances agentic capabilities in complex environments. My findings contribute to a deeper understanding of the comparative strengths and limitations\nof these reasoning approaches, providing valuable insights for future autonomous agent design.",
        "9": "RRdE: A Decision Making Framework for Language Agents in Interactive Environments. Xufeng Zhou, Linjing Li, D. Zeng. IEEE International Joint Conference on Neural Network, 2024.\nNumber of citations: 0\nAbstract: Large language models(LLMs) have demonstrated remarkable planning and reasoning abilities, particularly as few-shot learners, when utilizing in-context learning. However, since LLMs are not grounded during training, they still encounter difficulties when acting as agents in tasks that require interaction with the environment, especially in scenarios that involve long-term and multistep interactions. Even when provided with a complete game trajectory as context, LLMs struggle to comprehend the meaning of each interaction step, and may easily hallucinate and fail. To address these challenges, we introduce the RRdE (Reasoning and Replanning during Exploration), a framework inspired by planning theories, designed for reasoning about actions and planning subgoals in complex interactive environments. The RRdE method can integrate the long-term planning ability and tooluse ability of LLMs, and transform the long-term sequential decision problem into a relatively simple reasoning problem, thereby reducing the error behavior caused by excessive context. We devise a reflection-based goal decomposition and replanning scheme, which enables the agent to overcome the strict sub-goal dependency problem caused by long-term goal planning. Consequently, RRdE achieves state-of-the-art performance in the few-shot learning setting in both AlfWorld and ScienceWorld environments, accomplishing 132 out of 134 test tasks in AlfWorld, and obtaining an average score of 82.16 in the 30 more complex and challenging scientific tasks in ScienceWorld, successfully completing 7 tasks with a full score of 100."
    }
}