{
    "query": "Graph Neural Networks AND cognitive architectures AND human reasoning",
    "result": {
        "1": "Proceedings of the Sixteenth Annual Conference of the Cognitive Science Society. A. Ram, Kurt P. Eiselt. , 2019.\nNumber of citations: 119\nAbstract: Contents: Part I: Refereed Papers. M. Abu-Bakar, N. Chater, Distribution and Frequency: Modelling the Effects of Speaking Rate on Category Boundaries Using a Recurrent Neural Network. W. Ahn, J. Bailenson, B. Gordon, Causal Attribution as Mechanism-Based Story Construction: An Explanation of the Conjunction Fallacy and the Discounting Principle. B.G. Bara, M. Bucciarelli, P.N. Johnson-Laird, V. Lombardo, Mental Models in Propositional Reasoning. J.A. Barnden, S. Helmreich, E. Iverson, G.C. Stein, Combining Simulative and Metaphor-Based Reasoning About Beliefs. J. Batali, Artificial Evolution of Syntactic Aptitude. B. Bell, S. Kedar, R. Bareiss, Interactive Model-Driven Case Adaptation for Instructional Software Design. K. Bielaczyc, P.L. Pirolli, A.L. Brown, Collaborative Explanations and Metacognition: Identifying Successful Learning Activities in the Acquisition of Cognitive Skills. A. Blackwell, E. Bates, Inducing Agrammatic Profiles in Normals. S.B. Blessing, B.H. Ross,Problem Content Affects the Categorization and Solutions of Problems. N. Braisby, B. Franks, J. Hampton, On the Psychological Basis for Rigid Designation. W.F. Brewer, C.A. Chinn, The Theory-Ladenness of Data: An Experimental Demonstration. A. Brook ,Kant and Cognitive Science. D. Buckingham, T.R Shultz, A Connectionist Model of the Development of Velocity, Time, and Distance Concepts. J.A. Bullinaria ,Connectionist Modelling of Spelling. J.A. Bullinaria, Internal Representations of a Connectionist Model of Reading Aloud. C. Burgess, K. Lund, Multiple Constraints in Syntactic Ambiguity Resolution: A Connectionist Account of Psycholinguistic Data. C. Burgess, M.K. Tanenhaus, M. Hoffman, Parafoveal and Semantic Effects on Syntactic Ambiguity Resolution. B.D. Burns, K.J. Holyoak, Competing Models of Analogy: ACME Versus Copycat. M.H. Burstein, Case Age: Selecting the Best Exemplars for Plausible Reasoning Using Distance in Time or Space. J.G. Bush, H.M. Johnson, C.M. Seifert, The Implications of Corrections: Then Why Did You Mention It? M.D. Byrne, Integrating, Not Debating, Situated Action and Computational Models: Taking the Environment Seriously. R.M.J. Byrne, A. Tasso, Counterfactual Reasoning: Inferences From Hypothetical Conditionals. A. Cabrera, Functional and Conditional Equivalence: Conceptual Contributions From Behavior Analysis. P. Cairns, R. Shillcock, N. Chater, J. Levy,Lexical Segmentation: The Role of Sequential Statistics in Supervised and Un-Supervised Models. T. Carpenter, R. Alterman, A Taxonomy for Planned Reading. T.A. Cartwright, M.R. Brent, Segmenting Speech Without a Lexicon: Evidence for a Bootstrapping Model of Lexical Acquisition. J. Cassell, M. Stone, B. Douville, S. Prevost, B. Achorn, M. Steedman, N. Badler, C. Pelachaud, Modeling the Interaction Between Speech and Gesture. R. Catrambone, The Effects of Labels in Examples on Problem Solving Transfer. H. Chalupsky, S.C. Shapiro,SL: A Subjective, Intensional Logic of Belief. P.C-H. Cheng, An Empirical Investigation of Law Encoding Diagrams for Instruction. C.A. Chinn, Are Scientific Theories That Predict Data More Believable Than Theories That Retrospectively Explain Data? A Psychological Investigation. M.M. Chiu, J. Gutwill, The Architecture of Intuition: Converging Views From Physics Education and Linguistics. T.C. Clausner, Commonsense Knowledge and Conceptual Structure in Container Metaphors. C. Cleary, R. Bareiss, A Descriptive Model of Question Asking During Acquisition Interviews. J. Clement,Imagistic Simulation and Physical Intuition in Expert Problem Solving. A. Content, P. Sternon, Modelling Retroactive Context Effects in Spoken Word Recognition With a Simple Recurrent Network. A.T. Corbett, J.R. Anderson, V.H Carver, S.A. Brancolini, Individual Differences and Predictive Validity in Student Modeling. S. Coulson, N.V. Flor, Rational Choice and Framing Devices: Argumentation and Computer Programming. M.T. Cox,Machines That Forget: Learning From Retrieval Failure of Mis-Indexed Explanations. M.T. Cox, A. Ram, Failure-Driven Learning as Input Bias. R. Cox, K. Stenning, J. Oberlander, Graphical Effects in Learning Logic: Reasoning, Representation and Individual Differences. S. Dennis, The Null List Strength Effect in Recognition Memory: Environmental Statistics and Connectionist Accounts. S. Derry, K. Tookey, Effects of Collaborative Interaction and Computer Tool Use. S.M. Doane, Y.W. Sohn. D. Adams, D.S. McNamara, Learning From Instruction: A Comprehension-Based Approach. R. Elio, F.J. Pelletier, The Effect of Syntactic Form on Simple Belief Revisions and Updates. R.A. Engle, J.G. Greeno, Managing Disagreement in Intellectual Conversations Coordinating Interpersonal and Conceptual Concerns in the Collaborative Construction of Mathematical Explanations. J. Epelboim, H. Collewijn, E. Kowler, C.J. Erkelens, M. Edwards, Z. Pizlo, R.M. Steinman, Natural Oculomotor Performance in Looking and Tapping Tasks. J.M. Faries, K.R. Schlossberg, The Effect of Similarity on Memory for Prior Problems. R.W. Ferguson, MAGI: Analogy-Based Encoding Using Regularity and Symmetry. E.C. Ferstl, The Construction-Integration Model: A Framework for Studying Context Effects in Sentence Processing. E.C. Ferstl, Context Effects in Syntactic Ambiguity Resolution: The Location of Prepositional Phrase Attachment. S. Finch, N. Chater, Distributional Bootstrapping: From Word Class to Proto-Sentence. M.H. Fischer, Attention Allocation During Movement Preparation. K.D. Forbus, R.W. Ferguson, D. Gentner, Incremental Structure-Mapping. N. Forrester, K. Plunkett, Learning the Arabic Plural: The Case for Minority Default Mappings in Connectionist Networks. S. Fox, D. Leake, Using Introspective Reasoning to Guide Index Refinement in Case-Based Reasoning. G. Francis, S. Grossberg, How Do Representations of Visual Form Organize Our Percepts of Visual Motion? R.M. French, Dynamically Constraining Connectionist Networks to Produce Distributed, Orthogonal Representations to Reduce Catastrophic Interference. G. Gaskell, W. Marslen-Wilson, Inference Processes in Speech Perception. M. Gattis, K.J. Holyoak, How Graphs Mediate Analog and Symbolic Representation. D. Gentner, B.F. Bowdle, The Coherence Imbalance Hypothesis: A Functional Approach to Asymmetry in Comparison. E. Gibson, J. Loomis, A Corpus Analysis of Recency Preference and Predicate Proximity. S.A. Gilbert, W. Richards, Using Trajectory Mapping to Analyze Musical Intervals. S. Gillis, W. Daelemans, G. Durieux, Are Children 'Lazy Learners'? A Comparison of Natural and Machine Learning of Stress. J. Glasgow, Array Representations for Model-Based Spatial Reasoning. A. Gordon, P. Edwards, D. Sleeman, Y. Kodratoff, Scientific Discovery in a Space of Structural Models: An Example From the History of Solution Chemistry. A. Grunewald, S. Grossberg, Binding of Object Representations by Synchronous Cortical Dynamics Explains Temporal Order and Spatial Pooling Data. M. Harm, L. Altmann, M.S. Seidenberg, Using Connectionist Networks to Examine the Role of Prior Constraints in Human Learning. P.M. Hastings, S.L. Lytinen, Objects, Actions, Nouns, and Verbs. C. Hewson, Empirical Evidence Regarding the Folk Psychological Concept of Belief. C. Hewson, C. Vogel, Psychological Evidence for Assumptions of Path-Based Inheritance Reasoning. K. Hiraki, Abstraction of Sensory-Motor F",
        "2": "Neural-symbolic integration and the Semantic Web. P. Hitzler, Federico Bianchi, Monireh Ebrahimi, Md Kamruzzaman Sarker. Semantic Web, 2020.\nNumber of citations: 76\nAbstract: Symbolic Systems in Artificial Intelligence which are based on formal logic and deductive reasoning are fundamentally different from Artificial Intelligence systems based on artificial neural networks, such as deep learning approaches. The difference is not only in their inner workings and general approach, but also with respect to capabilities. Neural-symbolic Integration, as a field of study, aims to bridge between the two paradigms. In this paper, we will discuss neural-symbolic integration in its relation to the Semantic Web field, with a focus on promises and possible benefits for both, and report on some current research on the topic. Approaches in Artificial Intelligence (AI) based on machine learning, and in particular those employing artificial neural networks, differ fundamentally from approaches that leverage knowledge bases to perform logical deduction and reasoning. The former are connectionist or subsymbolic AI systems able to solve complex tasks over unstructured data using supervised or unsupervised learning, including problems which cannot reasonably be hand-coded by humans. Subsymbolic methods are generally robust against noise in training or input data and have recently, in the wake of deep learning, been shown to exceed human performance in tasks involving video, audio, and 1We focus herein on deductive reasoning. Logical inductive and abductive reasoning have also been looked at in the Semantic Web context, e.g. [22,14], but to keep the discussion concise, we have not included them in this treatise. text processing. The latter are symbolic systems that thrive under the presence of large amounts of structured data, including for agent planning, constraint solving, data management, integration and querying, and other traditional application areas of knowledge-based systems and formal semantics. Classical rule-based systems, ontologies, and knowledge graphs that power search and information retrieval across the Web are also types of symbolic AI systems. Symbolic and subsymbolic systems are rather complementary to each other. For example, the key strengths of subsymbolic systems are weaknesses of symbolic ones, and vice versa. Symbolic systems are brittle, i.e., susceptible to data noise or minor flaws in the logial encoding of a problem, which stands in contrast to the robustness of connectionist approaches. But subsymbolic systems are generally black boxes in the sense that 1570-0844/19/$27.50 c \u00a9 2019 \u2013 IOS Press and the authors. All rights reserved 2 Hitzler, Bianchi, Ebrahimi, Sarker / Neural-Symbolic Integration and the Semantic Web the systems cannot be inspected in ways that provide insight into their decisions (despite some recent progress on this in the wake of the explainable AI effort) while symbolic knowledge bases can in principle be inspected to interpret how a decision follows from input. Most importantly, symbolic and subsymbolic systems contrast in the types of problems and data they excel at. Scene recognition from images appears to be a problem which in general lies outside the capabilities of symbolic systems, for example, while complex planning scenarios appear to be outside the scope of current deep learning approaches. On a more technical level, symbolic and subsymbolic systems differ fundamentally in how they represent data, information, or knowledge. Symbolic systems typically utilize structured representation languages, e.g. stemming from formal logic and the subfield of AI known as knowledge representation and reasoning. Trainable artificial neural networks, on the other hand, typically use representations based on high-dimensional Euclidean space, i.e. real-valued vectors, matrices, etc., and it is by no means obvious how reconciliations between these representation forms can be designed. The complementary nature of these methods has drawn a divide in the rich field of AI. The divide is technical in nature, as symbol manipulation as captured by logical, deductive reasoning, which lies at the core of symbolic approaches, cannot be sufficiently performed using current subsymbolic systems. Moreover, the training to study subsymbolic systems (involving probability theory, statistics, linear algebra, and optimization) differs from symbolic systems (involving logic and propositional calculus, set and recursion theory, and advanced computability reasoning) so strongly that AI researchers tend to find a side of the divide based on their intellectual interests and background. The divide is also cultural in nature, one of mindsets and prior believes, that in the past could sometimes split the academic AI research community by provoking (heated) fundamental discus2The topic is being investigated, of course, and some recent progress is made. E.g., [1] reports on an application of deep learning to planning, and explicitly frames it as work towards bridging the \u201csubsymbolic-symbolic boundary.\u201d 3It is possible to establish a formal, mathematical bridge in some cases, as e.g. laid out in [31], but so far with limited applicability [3]. sions. The divide is even geographical, where the European Union holds a much higher prevalence of researchers working on symbolic approaches than in the United States. Neural-Symbolic Integration [2,4,28,16], as a field of research, addresses fundamental problems related to building a technical bridge between the symbolic and subsymbolic sides of the divide. The promises from a successful bridging of the divide are plenty. In the abstract, one could hope for bestof-both-worlds systems, which combine the transparency and reasoning-ability of symbolic systems with the robustness and learning-capabilities of subsymbolic ones. As such, integrated symbolicsubsymbolic systems may be able to address the knowledge acquisition bottleneck faced by symbolic systems, learn to perform advanced logical or symbolic reasoning tasks even in the presence of noisy or uncertain facts, and even yield self-explanatory subsymbolic models. This is the promise of added value of neural-symbolic integration research for Computer Science. And also more fundamentally, a bridging may shed insights into how natural (human) neural networks can perform tasks as witnessed by homo sapiens pursuing mathematics, formal logic, and other pursuits that we, introspectively, see as symbolic in nature; this is a basic research problem for Cognitive Science as a discipline. In the following, we will first lay out, in more detail, promises and possible benefits of neuralsymbolic integration research for the Semantic Web. Then we will look at potential benefits of Semantic Web and neural-symbolic integration research for deep learning. Finally, we will also provide brief pointers to some current research going on in relation to this theme. 1. Benefits of Neural-Symbolic Integration for the Semantic Web One of the issues that plagues the Semantic Web (as well as many other fields in Computer Science and its applications) is the knowledge acquisition bottleneck. It refers to the difficult issue of encoding or otherwise storing knowledge, as structured information, for use in Computer Science 4See also http://www.neural-symbolic.org/ Hitzler, Bianchi, Ebrahimi, Sarker / Neural-Symbolic Integration and the Semantic Web 3 applications. The manual encoding of such information, e.g. from human experts\u2019 knowledge, is a very slow and time-consuming, thus costly, process involving both topic experts and knowledge engineers. At the same time, automated methods are a far cry from producing artifacts (e.g., from textbooks, technical documentations, and other written sources) which would be of sufficient quality for use in intelligent systems applications based on logical inference, such as expert systems, or for data curation and integration. The underpinnings of key Semantic Web standards, such as RDF [9] and OWL [29], are explicitly logical, which reflects that Semantic Web applications often rely on high data (and schema/ontology) quality, similar to knowledge bases used primarily for deductive reasoning. The knowledge acquisition bottleneck in the Semantic Web field is very noticeable, e.g., given that the creation of ontologies as well as the creation of high-quality knowledge graphs involves high amounts of human export labour and is correspondingly expensive. The promise of integrated neural-symbolic systems is that they would be capable of both learning and (deductive) reasoning, and thus that they would be able to acquire, through machine learning, knowledge which is of sufficiently high quality to perform deductive reasoning. This anticipated capability directly addresses the knowledge acquisition bottleneck. There is, thus, a promise in this line of work that integrated neural-symbolic systems will lead to \u2013 better methods for automated ontology construction, \u2013 better methods for ontology population (and, thus, knowledge graph construction), \u2013 better methods for ontology alignment, \u2013 better methods for assessing the quality of knowledge graph content, and similar major lines of research central to the Semantic Web field. At the same time, integrated neural-symbolic systems carry the promise of being able to perform deductive reasoning \u2013 after training \u2013 using a (highly parallel) artificial neural network architecture. Consequently, reasoning using such systems can be expected to be extremely fast. This contrasts with traditional deductive reasoning methods, which are usually designed to be provably sound and complete but suffer from long algorithm runtimes. While there has been significant progress on developing highly efficient deductive reasoning engines for Semantic Web content, this remains an issue given ever-increasing availability of data. In fact, the underlying problem is fundamental, as sound and complete reasoning over Semantic Web data necessarily suffers from high computational complexity [30]. Integrated neural-symbolic systems would perform reasoning after training, and presumabl",
        "3": "System 1 + System 2 = Better World: Neural-Symbolic Chain of Logic Reasoning. Wenyue Hua, Yongfeng Zhang. Conference on Empirical Methods in Natural Language Processing, 2022.\nNumber of citations: 21\nAbstract: Logical reasoning is a challenge for many current NLP neural network models since it requires more than the ability of learning informative representations from data. Inspired by the Dual Process Theory in cognitive science \u2014 which proposes that human cognition process involves two stages: an intuitive, unconscious and fast process relying on perception called System 1, and a logical, conscious and slow process performing complex reasoning called System 2 \u2014 we leverage neural logic reasoning (System 2) on top of the representation learning models (System 1), which conducts explicit neural-based differentiable logical reasoning on top of the representations learned by the base neural models. Based on experiments on the commonsense knowledge graph completion task, we show that the two-system architecture always improves from its System 1 model alone. Experiments also show that both the rule-driven logical regularizer and the data-driven value regularizer are important and the performance improvement is marginal without the two regularizers, which indicates that learning from both logical prior and training data is important for reasoning tasks.",
        "4": "A Practical Guide to Hybrid Natural Language Processing: Combining Neural Models and Knowledge Graphs for NLP. Jos\u00e9 Manu\u00e9l G\u00f3mez-P\u00e9rez, R. Denaux, Andres Garcia-Silva. , 2020.\nNumber of citations: 14\nAbstract: None",
        "5": "Neuro Symbolic AI in personalized mental health therapy: Bridging cognitive science and computational psychiatry. Anil Kumar. World Journal of Advanced Research and Reviews, 2023.\nNumber of citations: 6\nAbstract: Personalized mental health therapy has gained increasing attention as advancements in artificial intelligence (AI) enable tailored treatment strategies based on individual cognitive and emotional profiles. Neuro-symbolic AI, a hybrid approach combining symbolic reasoning and neural networks, offers a promising solution for bridging cognitive science and computational psychiatry. Unlike conventional AI models that rely solely on deep learning, neuro-symbolic AI integrates human-interpretable knowledge representations with data-driven learning, enhancing the adaptability and explainability of AI-driven mental health interventions. This study explores the role of neuro-symbolic AI in revolutionizing personalized mental health care by integrating cognitive theories, structured knowledge graphs, and deep learning-based predictive modeling. By leveraging structured symbolic reasoning alongside probabilistic inference, neuro-symbolic systems enhance diagnostic accuracy, facilitate adaptive therapy recommendations, and improve patient-clinician interactions. Applications include AI-assisted cognitive behavioral therapy (CBT), personalized mood stabilization strategies, and early detection of mental health disorders through multimodal data fusion from speech, facial expressions, and physiological biomarkers. Furthermore, we examine the advantages of neuro-symbolic AI in addressing key challenges in computational psychiatry, including model interpretability, causal reasoning in mental health diagnosis, and the integration of psychological theories into AI frameworks. A comparative analysis of neuro-symbolic AI versus purely neural-based models highlights its superior capacity for reasoning, transparency, and personalized therapeutic adaptation. Future directions focus on refining hybrid AI architectures, integrating real-time patient feedback for dynamic therapy adjustment, and addressing ethical concerns related to AI-driven mental health interventions.",
        "6": "Schema Inference for Interpretable Image Classification. Haofei Zhang, Mengqi Xue, Xiaokang Liu, Kaixuan Chen, Jie Song, Mingli Song. International Conference on Learning Representations, 2023.\nNumber of citations: 3\nAbstract: In this paper, we study a novel inference paradigm, termed as schema inference, that learns to deductively infer the explainable predictions by rebuilding the prior deep neural network (DNN) forwarding scheme, guided by the prevalent philosophical cognitive concept of schema. We strive to reformulate the conventional model inference pipeline into a graph matching policy that associates the extracted visual concepts of an image with the pre-computed scene impression, by analogy with human reasoning mechanism via impression matching. To this end, we devise an elaborated architecture, termed as SchemaNet, as a dedicated instantiation of the proposed schema inference concept, that models both the visual semantics of input instances and the learned abstract imaginations of target categories as topological relational graphs. Meanwhile, to capture and leverage the compositional contributions of visual semantics in a global view, we also introduce a universal Feat2Graph scheme in SchemaNet to establish the relational graphs that contain abundant interaction information. Both the theoretical analysis and the experimental results on several benchmarks demonstrate that the proposed schema inference achieves encouraging performance and meanwhile yields a clear picture of the deductive process leading to the predictions. Our code is available at https://github.com/zhfeing/SchemaNet-PyTorch.",
        "7": "Scalable Multi-FPGA HPC Architecture for Associative Memory System. Deyu Wang, Xiaoze Yan, Yu Yang, D. Stathis, Ahmed Hemani, A. Lansner, Jiawei Xu, Lirong Zheng, Zhuo Zou. IEEE Transactions on Biomedical Circuits and Systems, 2024.\nNumber of citations: 2\nAbstract: Associative memory is a cornerstone of cognitive intelligence within the human brain. The\u00a0Bayesian confidence propagation neural network (BCPNN), a cortex-inspired model with high biological plausibility, has proven effective in emulating high-level cognitive functions like associative memory. However, the current approach using GPUs to simulate BCPNN-based associative memory tasks encounters challenges in latency and power efficiency as the model size scales. This work proposes a scalable multi-FPGA high performance computing (HPC) architecture designed for the associative memory system. The\u00a0architecture integrates a set of hypercolumn unit (HCU) computing cores for intra-board online learning and inference, along with a spike-based synchronization scheme for inter-board communication among multiple FPGAs. Several design strategies, including population-based model mapping, packet-based spike synchronization, and cluster-based timing optimization, are presented to facilitate the multi-FPGA implementation. The\u00a0architecture is implemented and validated on two Xilinx Alveo U50 FPGA cards, achieving a maximum model size of 200$\\boldsymbol{\\times}$10 and a peak working frequency of 220 MHz for the associative memory system. Both the memory-bounded spatial scalability and compute-bounded temporal scalability of the architecture are evaluated and optimized, achieving a maximum scale-latency ratio (SLR) of 268.82 for the two-FPGA implementation. Compared to a two-GPU counterpart, the two-FPGA approach demonstrates a maximum latency reduction of 51.72$\\boldsymbol{\\times}$ and a power reduction exceeding 5.28$\\boldsymbol{\\times}$ under the same network configuration. Compared with the state-of-the-art works, the two-FPGA implementation exhibits a high pattern storage capacity for the associative memory task.",
        "8": "Knowledge distillation as a pathway toward next-generation intelligent ecohydrological modeling systems. Long Jiang, Yang Yang, Ting Fong May Chui, Morgan Thornwell, Hoshin Vijai Gupta. , 2025.\nNumber of citations: 0\nAbstract: Simulating ecohydrological processes is essential for understanding complex environmental systems and guiding sustainable management amid accelerating climate change and human pressures. Process-based models provide physical realism but can suffer from structural rigidity, high computational costs, and complex calibration, while machine learning (ML) methods are efficient and flexible yet often lack interpretability and transferability. We propose a unified three-phase framework that integrates process-based models with ML and progressively embeds them into artificial intelligence (AI) through knowledge distillation. Phase I, behavioral distillation, enhances process models via surrogate learning and model simplification to capture key dynamics at lower computational cost. Phase II, structural distillation, reformulates process equations as modular components within a graph neural network (GNN), enabling multiscale representation and seamless integration with ML models. Phase III, cognitive distillation, embeds expert reasoning and adaptive decision-making into intelligent modeling agents using the Eyes-Brain-Hands-Mouth architecture. Demonstrations for the Samish watershed highlight the framework's applicability to ecohydrological modeling, showing that it can reproduce process-based model outputs, improve predictive accuracy, and support scenario-based decision-making. The framework offers a scalable and transferable pathway toward next-generation intelligent ecohydrological modeling systems, with the potential extension to other process-based domains.",
        "9": "Artificial neural networks - ICANN 2009 : 19th international conference, Limassol, Cyprus, September 14-17, 2009 : proceedings. C. Alippi. International Conference on Artificial Neural Networks, 2009.\nNumber of citations: 0\nAbstract: None",
        "10": "Driving decision making of autonomous vehicles based on deep reinforcement learning with prefrontal cortex-like cognition. Jialin Liu, Xiaolan Wang, Yansong Wang, Jianxun Xu. Proceedings of the Institution of mechanical engineers. Part D, journal of automobile engineering, 2025.\nNumber of citations: 0\nAbstract: Safe and efficient decision-making of autonomous vehicles in complex dynamic scenarios requires a decision-making system with human-like cognitive ability, however, existing deep reinforcement learning methods suffer from insufficient generalization ability of unknown scenarios and exploration-exploitation imbalance. In order to solve the above problems, this study proposes a novel prefrontal cortex (PFC) decision-making model, which builds a multi-module synergistic cognitive architecture by modeling the spatio-temporal reasoning of the lateral prefrontal cortex (LPFC), the reward prediction of the medial prefrontal cortex (MPFC), and the adaptive adjustment function of the anterior cingulate cortex (ACC). The innovations are fusion of graph convolutional network (GCN) and long short-term memory network (LSTM) to capture vehicle interaction features; introduction of unsupervised clustering and deep belief network (DBN) to achieve metacognitive planning of action-reward causal association, proposing a dynamic exploration rate regulation mechanism based on alertness, and realizing strategy optimization in complex scenarios through dopamine-based reward prediction error. In this study, this study test the performance of the method in highway and ring intersection scenarios and compare it with existing deep reinforcement learning (DRL) and graph reinforcement learning (GRL) methods. The experimental results show that the PFC model can perform spatio-temporal and task reasoning, and is able to make better decisions in complex and changing scenarios, which significantly improves the efficiency of access. This study can provide reference value for the development of biological neural models and promote their application in dynamic traffic interaction scenarios."
    }
}