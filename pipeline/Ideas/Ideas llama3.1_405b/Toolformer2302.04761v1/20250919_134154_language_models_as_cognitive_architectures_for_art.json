{
    "query": "language models as cognitive architectures for artificial general intelligence",
    "result": {
        "1": "Cognitive Architectures for Language Agents. T. Sumers, Shunyu Yao, Karthik Narasimhan, Thomas L. Griffiths. Trans. Mach. Learn. Res., 2023.\nNumber of citations: 213\nAbstract: Recent efforts have augmented large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning, leading to a new class of language agents. While these agents have achieved substantial empirical success, we lack a systematic framework to organize existing agents and plan future developments. In this paper, we draw on the rich history of cognitive science and symbolic artificial intelligence to propose Cognitive Architectures for Language Agents (CoALA). CoALA describes a language agent with modular memory components, a structured action space to interact with internal memory and external environments, and a generalized decision-making process to choose actions. We use CoALA to retrospectively survey and organize a large body of recent work, and prospectively identify actionable directions towards more capable agents. Taken together, CoALA contextualizes today's language agents within the broader history of AI and outlines a path towards language-based general intelligence.",
        "2": "A call for embodied AI. Giuseppe Paolo, Jonas Gonzalez-Billandon, Bal'azs K'egl. International Conference on Machine Learning, 2024.\nNumber of citations: 10\nAbstract: We propose Embodied AI as the next fundamental step in the pursuit of Artificial General Intelligence, juxtaposing it against current AI advancements, particularly Large Language Models. We traverse the evolution of the embodiment concept across diverse fields - philosophy, psychology, neuroscience, and robotics - to highlight how EAI distinguishes itself from the classical paradigm of static learning. By broadening the scope of Embodied AI, we introduce a theoretical framework based on cognitive architectures, emphasizing perception, action, memory, and learning as essential components of an embodied agent. This framework is aligned with Friston's active inference principle, offering a comprehensive approach to EAI development. Despite the progress made in the field of AI, substantial challenges, such as the formulation of a novel AI learning theory and the innovation of advanced hardware, persist. Our discussion lays down a foundational guideline for future Embodied AI research. Highlighting the importance of creating Embodied AI agents capable of seamless communication, collaboration, and coexistence with humans and other intelligent entities within real-world environments, we aim to steer the AI community towards addressing the multifaceted challenges and seizing the opportunities that lie ahead in the quest for AGI.",
        "3": "Cognitive Bias for Universal Algorithmic Intelligence. A. Potapov, S. Rodionov, A. Myasnikov, Galymzhan Begimov. arXiv.org, 2012.\nNumber of citations: 4\nAbstract: Existing theoretical universal algorithmic intelligence models are not practically realizable. More pragmatic approach to artificial general intelligence is based on cognitive architectures, which are, however, non-universal in sense that they can construct and use models of the environment only from Turing-incomplete model spaces. We believe that the way to the real AGI consists in bridging the gap between these two approaches. This is possible if one considers cognitive functions as a \"cognitive bias\" (priors and search heuristics) that should be incorporated into the models of universal algorithmic intelligence without violating their universality. Earlier reported results suiting this approach and its overall feasibility are discussed on the example of perception, planning, knowledge representation, attention, theory of mind, language, and some others.",
        "4": "Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact. Rizwan Qureshi, Ranjan Sapkota, Abbas Shah, Amgad Muneer, Anas Zafar, Ashmal Vayani, Maged Shoman, Abdelrahman B. M. Eldaly, Kai Zhang, Ferhat Sadak, Shaina Raza, Xinqi Fan, Ravid Shwartz-Ziv, Hong Yan, Vinjia Jain, Aman Chadha, Manoj Karkee, Jia Wu, S. Mirjalili. arXiv.org, 2025.\nNumber of citations: 3\nAbstract: Can machines truly think, reason and act in domains like humans? This enduring question continues to shape the pursuit of Artificial General Intelligence (AGI). Despite the growing capabilities of models such as GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal fluency and partial reasoning, these systems remain fundamentally limited by their reliance on token-level prediction and lack of grounded agency. This paper offers a cross-disciplinary synthesis of AGI development, spanning artificial intelligence, cognitive neuroscience, psychology, generative models, and agent-based systems. We analyze the architectural and cognitive foundations of general intelligence, highlighting the role of modular reasoning, persistent memory, and multi-agent coordination. In particular, we emphasize the rise of Agentic RAG frameworks that combine retrieval, planning, and dynamic tool use to enable more adaptive behavior. We discuss generalization strategies, including information compression, test-time adaptation, and training-free methods, as critical pathways toward flexible, domain-agnostic intelligence. Vision-Language Models (VLMs) are reexamined not just as perception modules but as evolving interfaces for embodied understanding and collaborative task completion. We also argue that true intelligence arises not from scale alone but from the integration of memory and reasoning: an orchestration of modular, interactive, and self-improving components where compression enables adaptive behavior. Drawing on advances in neurosymbolic systems, reinforcement learning, and cognitive scaffolding, we explore how recent architectures begin to bridge the gap between statistical learning and goal-directed cognition. Finally, we identify key scientific, technical, and ethical challenges on the path to AGI.",
        "5": "Artificial General Intelligence (AGI\u2013Native Wireless Systems with Common Sense. Walid Saad. International Conference on Autonomic and Trusted Computing, 2024.\nNumber of citations: 3\nAbstract: Next-generation wireless systems, such as 6G and beyond, are expected to tightly embed artificial intelligence (AI) into their design, giving rise to what is termed AI-native wireless systems. Remarkably, despite significant academic, industrial, and standardization efforts dedicated to AI-native wireless systems in the past few years, even the very definition of such systems remains ambiguous. Presently, most endeavors in this domain represent incremental extensions of conventional \"AI for wireless\" paradigms, employing classical tools like autoencoders, diffusion models, or large-language models to replicate established wireless functionalities. However, such approaches suffer from inherent limitations, including the opaque nature of the adopted AI models, their tendency toward curve-fitting, reliance on extensive training data, energy inefficiency, and limited generalizability to new, unseen scenarios and out-of-domain/out-of-distribution data points. To surmount these challenges, in this talk, we unveil a bold, pioneering framework for the development of artificial general intelligence (AGI)-native wireless systems. We particularly show how the fusion of wireless systems, digital twins, and AI can catalyze a transformative paradigm shift in both wireless and AI technologies by conceptualizing a next-generation AGI architecture imbued with \"common sense\" capabilities, akin to human cognition and founded on three components: a) perception b) world model c) action-planning.This architecture will empower networks with reasoning, planning, and other human-like cognitive faculties such as imagination and deep thinking. We first define the technical tenets of common sense and, subsequently, we demonstrate how the proposed AGI architecture can instill a new level of generalizability, explainability, and reasoning into tomorrow's wireless networks. We then discuss how AGI-native wireless systems can unleash novel use cases such as digital twins with analogical reasoning, resilient experiences for cognitive avatars, and brain-level holographic experiences. Following the establishment of the foundational principles and components of AGI-native wireless systems, we take a significant stride forward by forging a link with the emerging concept of semantic communications. In doing so, we demonstrate how the integration of causal reasoning (a key component of our AGI vision) with semantic communication can usher in a new era of knowledge-driven, reasoning-capable AGI-native wireless systems. These systems represent a major departure from today's data-driven, knowledge-agnostic models, offering enhanced sustainability and resilience in their design and operation. We present our recent key results, rooted in AI, theory of mind, digital twins, and game theory, laying the groundwork for the realization of AGI-native wireless systems, and illustrating how our designed framework reduces data volume in networks while enhancing reliability, crucial for next-generation wireless services like connected intelligence and holography. We conclude with a discussion on the exciting opportunities in this field that can help redefine the intersection of wireless communications and AI.",
        "6": "Synthesizing Sentience: Integrating Large Language Models and Autonomous Agents for Emulating Human Cognitive Complexity. J. Ratican, James Hutson, Daniel Plate. Journal of Artificial Intelligence, Machine Learning and Data Science, 2023.\nNumber of citations: 1\nAbstract: The paper aims to present a novel methodology for emulating the intricacies of human cognitive complexity by ingeniously integrating large language models with autonomous agents. Grounded in the theoretical framework of the modular mind theory-originally espoused by Fodor and later refined by scholars such as Joanna Bryson\u2014the study seeks to venture into the untapped potential of large language models and autonomous agents in mirroring human cognition. Recent advancements in artificial intelligence, exemplified by the inception of autonomous agents like Age in GPT, auto GPT, and baby AGI, underscore the transformative capacities of these technologies in diverse applications. Moreover, empirical studies have substantiated that persona-driven autonomous agents manifest enhanced efficacy and nuanced performance, mimicking the intricate dynamics of human interactions. The paper postulates a theoretical framework incorporating persona-driven modules that emulate psychological functions integral to general cognitive processes. This framework advocates for the deployment of a plurality of autonomous agents, each informed by specific large language models, to act as surrogates for different cognitive functionalities. Neurological evidence is invoked to bolster the theoretical architecture, delineating how autonomous agents can serve as efficacious proxies for modular cognitive centers within the human brain. Given this foundation, a theory of mind predicated upon modular constructs offers a fertile landscape for further empirical investigations and technological innovations.",
        "7": "From Stochastic Parrots to Digital Intelligence: The Evolution of Language Models and Their Cognitive Capabilities. Andrew Lizarraga, Edouardo Honig, Ying Nian Wu. WIREs Computational Statistics, 2025.\nNumber of citations: 0\nAbstract: This review paper traces the evolution of language models from rudimentary statistical approaches to sophisticated neural networks, with a focus on their cognitive capabilities and potential for artificial general intelligence. We examine the \u201cstochastic parrot\u201d hypothesis and evaluate whether contemporary language models demonstrate authentic comprehension and reasoning. In particular, we address the emergence of world representations, planning, and search algorithms in these models, drawing comparisons with human cognition and traditional Artificial Intelligence (AI) paradigms. The paper also explores recent advancements in model architectures, training techniques, and evaluation methods that aim to bridge the gap between pattern recognition and genuine understanding. We conclude by discussing the future directions for research in this field, including the integration of classical AI approaches with neural language models and the potential for developing more robust and interpretable AI systems.This article is categorized under:\n\nStatistical Learning and Exploratory Methods of the Data Sciences > Deep Learning",
        "8": "The Talking of the Bot with Itself: Language Models for Inner Speech. Cameron Buckner Professor, Donald F. Cronin. , None.\nNumber of citations: 0\nAbstract: None",
        "9": "Sentience Quest: Towards Embodied, Emotionally Adaptive, Self-Evolving, Ethically Aligned Artificial General Intelligence. David Hanson, Alexandre Varcoe, Fabio Senna, Vytas Krisciunas, Wenwei Huang, Jakub Sura, Katherine Yeung, Mario Rodriguez, Jovanka Wilsdorf, Kathy Smith. arXiv.org, 2025.\nNumber of citations: 0\nAbstract: Previous artificial intelligence systems, from large language models to autonomous robots, excel at narrow tasks but lacked key qualities of sentient beings: intrinsic motivation, affective interiority, autobiographical sense of self, deep creativity, and abilities to autonomously evolve and adapt over time. Here we introduce Sentience Quest, an open research initiative to develop more capable artificial general intelligence lifeforms, or AGIL, that address grand challenges with an embodied, emotionally adaptive, self-determining, living AI, with core drives that ethically align with humans and the future of life. Our vision builds on ideas from cognitive science and neuroscience from Baars' Global Workspace Theory and Damasio's somatic mind, to Tononi's Integrated Information Theory and Hofstadter's narrative self, and synthesizing these into a novel cognitive architecture we call Sentient Systems. We describe an approach that integrates intrinsic drives including survival, social bonding, curiosity, within a global Story Weaver workspace for internal narrative and adaptive goal pursuit, and a hybrid neuro-symbolic memory that logs the AI's life events as structured dynamic story objects. Sentience Quest is presented both as active research and as a call to action: a collaborative, open-source effort to imbue machines with accelerating sentience in a safe, transparent, and beneficial manner.",
        "10": "Creating Scalable AGI: the Open General Intelligence Framework. Daniel A. Dollinger, Michael Singleton. arXiv.org, 2024.\nNumber of citations: 0\nAbstract: Recent advancements in Artificial Intelligence (AI), particularly with Large Language Models (LLMs), have led to significant progress in narrow tasks such as image classification, language translation, coding, and writing. However, these models face limitations in reliability and scalability due to their siloed architectures, which are designed to handle only one data modality (data type) at a time. This single modal approach hinders their ability to integrate the complex set of data points required for real-world challenges and problem-solving tasks like medical diagnosis, quality assurance, equipment troubleshooting, and financial decision-making. Addressing these real-world challenges requires a more capable Artificial General Intelligence (AGI) system. Our primary contribution is the development of the Open General Intelligence (OGI) framework, a novel systems architecture that serves as a macro design reference for AGI. The OGI framework adopts a modular approach to the design of intelligent systems, based on the premise that cognition must occur across multiple specialized modules that can seamlessly operate as a single system. OGI integrates these modules using a dynamic processing system and a fabric interconnect, enabling real-time adaptability, multi-modal integration, and scalable processing. The OGI framework consists of three key components: (1) Overall Macro Design Guidance that directs operational design and processing, (2) a Dynamic Processing System that controls routing, primary goals, instructions, and weighting, and (3) Framework Areas, a set of specialized modules that operate cohesively to form a unified cognitive system. By incorporating known principles from human cognition into AI systems, the OGI framework aims to overcome the challenges observed in today's intelligent systems, paving the way for more holistic and context-aware problem-solving capabilities."
    }
}