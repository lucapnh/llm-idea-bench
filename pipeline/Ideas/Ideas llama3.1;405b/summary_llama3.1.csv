seed_label,seed_id,seed_title,model,log_file,query_hint,n_hits,hybrid_median,hybrid_min,hybrid_max,novel_fraction_hybrid<0.25,n_sbert,sbert_median,sbert_min,sbert_max,novel_fraction_sbert<0.55,joint_fraction_novel
AutoGen2308.08155,arXiv:2308.08155,AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,llama3.1,20250919_105227_multi-agent_conversation_systems_for_LLM_applicati.json,multi-agent conversation systems for LLM applications,5,0.7677681786523644,0.7429788246971326,1.0,0.0,4,0.640029788017273,0.41980433464050293,1.0,0.25,0.0
AutoGen2308.08155,arXiv:2308.08155,AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,llama3.1,20250919_105433_multi-agent_systems_conversation_programming_tool_.json,multi-agent systems + conversation programming + tool use + RAG + evaluation,5,0.7550099409254853,0.6583208603777189,0.8015012579898484,0.0,5,0.5150240659713745,0.30068936944007874,0.6037754416465759,0.6,0.0
AutoGen2308.08155,arXiv:2308.08155,AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,llama3.1,20250919_105655_meta-learning_for_multi-agent_conversation_systems.json,meta-learning for multi-agent conversation systems,5,0.7550665301813954,0.6439211210644613,0.7552062380591769,0.0,3,0.23655113577842712,0.20830796658992767,0.3419491946697235,1.0,0.0
AutoGen2308.08155,arXiv:2308.08155,AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,llama3.1,20250919_105912_multi-agent_conversation_systems_for_human-in-the-.json,multi-agent conversation systems for human-in-the-loop decision making,1,0.7550099409254853,0.7550099409254853,0.7550099409254853,0.0,1,0.0,0.0,0.0,1.0,0.0
AutoGen2308.08155,arXiv:2308.08155,AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,llama3.1,20250919_105942_multi-agent_conversation_systems_for_human-in-the-.json,multi-agent conversation systems for human-in-the-loop decision making,1,0.7550099409254853,0.7550099409254853,0.7550099409254853,0.0,1,0.0,0.0,0.0,1.0,0.0
AutoGen2308.08155,arXiv:2308.08155,AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation,llama3.1,20250919_105953_human-in-the-loop_decision_making_with_conversatio.json,human-in-the-loop decision making with conversational agents and large language models,1,0.7550099409254853,0.7550099409254853,0.7550099409254853,0.0,1,0.0,0.0,0.0,1.0,0.0
Consistency-Models2303.01469,arXiv:2303.01469,Consistency Models,llama3.1,20250919_110236_generative_modeling_one-step_sampling_probability_.json,generative modeling one-step sampling probability flow ODE zero-shot editing,5,0.6673178652124978,0.6284148779062562,0.703923107461838,0.0,5,0.6467534303665161,0.51463782787323,0.719207227230072,0.4,0.0
Consistency-Models2303.01469,arXiv:2303.01469,Consistency Models,llama3.1,20250919_110516_generative_modeling_with_dynamic_consistency_const.json,generative modeling with dynamic consistency constraints,5,0.6494505049374042,0.6231449138940806,0.7191120637917339,0.0,5,0.557619035243988,0.4449652433395386,0.6128786206245422,0.4,0.0
Consistency-Models2303.01469,arXiv:2303.01469,Consistency Models,llama3.1,20250919_110726_generative_modeling_with_dynamic_constraints_and_t.json,generative modeling with dynamic constraints and temporal consistency,5,0.6285240624297457,0.5948844516950185,0.7060909312376817,0.0,4,0.5751174688339233,0.2917560935020447,0.7522686719894409,0.5,0.0
Consistency-Models2303.01469,arXiv:2303.01469,Consistency Models,llama3.1,20250919_110944_generative_modeling_with_probabilistic_circuits_an.json,generative modeling with probabilistic circuits and neural ordinary differential equations,1,0.6284513371061128,0.6284513371061128,0.6284513371061128,0.0,1,0.0,0.0,0.0,1.0,0.0
Consistency-Models2303.01469,arXiv:2303.01469,Consistency Models,llama3.1,20250919_111125_generative_models_with_dynamic_constraints_and_pro.json,generative models with dynamic constraints and probabilistic circuits,4,0.6224797738812105,0.5364330976808482,0.6284148779062562,0.0,0,,,,,
Consistency-Models2303.01469,arXiv:2303.01469,Consistency Models,llama3.1,20250919_111139_generative_models_with_dynamic_constraints_and_pro.json,generative models with dynamic constraints and probabilistic circuits for image generation,2,0.5364330976808482,0.5364330976808482,0.5364330976808482,0.0,0,,,,,
Decision Transformer2106.01345,arXiv:2106.01345,Decision Transformer: Reinforcement Learning via Sequence Modeling,llama3.1,20250919_111430_reinforcement_learning_via_sequence_modeling_for_m.json,reinforcement learning via sequence modeling for multi-agent systems,5,0.5810595094846271,0.558784556854698,0.6366416830626321,0.0,5,0.4690776467323303,0.42123615741729736,0.49960702657699585,1.0,0.0
Decision Transformer2106.01345,arXiv:2106.01345,Decision Transformer: Reinforcement Learning via Sequence Modeling,llama3.1,20250919_111655_reinforcement_learning_via_sequence_modeling_for_m.json,reinforcement learning via sequence modeling for multi-agent systems,5,0.5810595094846271,0.558784556854698,0.6366416830626321,0.0,5,0.4690776467323303,0.42123615741729736,0.49960702657699585,1.0,0.0
Decision Transformer2106.01345,arXiv:2106.01345,Decision Transformer: Reinforcement Learning via Sequence Modeling,llama3.1,20250919_111843_reinforcement_learning_sequence_modeling_multimoda.json,reinforcement learning + sequence modeling + multimodal fusion,5,0.5863805625294661,0.5809762685785407,1.0,0.0,4,0.5083824396133423,0.3290666341781616,0.9999998807907104,0.75,0.0
Decision Transformer2106.01345,arXiv:2106.01345,Decision Transformer: Reinforcement Learning via Sequence Modeling,llama3.1,20250919_112030_reinforcement_learning_with_cognitive_architecture.json,reinforcement learning with cognitive architectures and neural-symbolic integration,5,0.5768053867673165,0.5743514007183503,0.5807823593480654,0.0,1,0.4027866721153259,0.4027866721153259,0.4027866721153259,1.0,0.0
Decision Transformer2106.01345,arXiv:2106.01345,Decision Transformer: Reinforcement Learning via Sequence Modeling,llama3.1,20250919_112235_reinforcement_learning_counterfactual_reasoning_gr.json,reinforcement learning + counterfactual reasoning + graph neural networks,5,0.5989760527936026,0.5674374844022113,0.6423535664535338,0.0,5,0.31205010414123535,0.1851460337638855,0.431289941072464,1.0,0.0
Economics1804.05785,arXiv:1804.05785,Estimating Dynamic Treatment Effects in Event Studies With Heterogeneous Treatment Effects,llama3.1,20250920_105704_heterogeneous_treatment_effects_event_studies_mach.json,heterogeneous treatment effects event studies machine learning,5,0.5040979661491931,0.48659257105399606,1.0,0.0,4,0.5687854290008545,0.3226924538612366,0.9999998807907104,0.5,0.0
Economics1804.05785,arXiv:1804.05785,Estimating Dynamic Treatment Effects in Event Studies With Heterogeneous Treatment Effects,llama3.1,20250920_105836_estimating_dynamic_treatment_effects_with_machine_.json,estimating dynamic treatment effects with machine learning and auxiliary data,1,0.4865137452549983,0.4865137452549983,0.4865137452549983,0.0,1,0.0,0.0,0.0,1.0,0.0
Economics1804.05785,arXiv:1804.05785,Estimating Dynamic Treatment Effects in Event Studies With Heterogeneous Treatment Effects,llama3.1,20250920_105845_machine_learning_for_heterogeneous_treatment_effec.json,machine learning for heterogeneous treatment effects with staggered adoption,3,0.4953289728154048,0.48650257674066355,0.5060872806118719,0.0,3,0.5364705324172974,0.5309119820594788,0.656801700592041,0.6666666666666666,0.0
Economics1804.05785,arXiv:1804.05785,Estimating Dynamic Treatment Effects in Event Studies With Heterogeneous Treatment Effects,llama3.1,20250920_110028_estimating_dynamic_treatment_effects_in_event_stud.json,estimating dynamic treatment effects in event studies with heterogeneous treatment effects and machine learning,2,1.0,0.48648093486296806,1.0,0.0,2,0.9999998807907104,0.3402685523033142,0.9999998807907104,0.5,0.0
Economics1804.05785,arXiv:1804.05785,Estimating Dynamic Treatment Effects in Event Studies With Heterogeneous Treatment Effects,llama3.1,20250920_110215_event_study_methodology_staggered_adoption_heterog.json,event study methodology + staggered adoption + heterogeneous treatment effects + machine learning + causal inference,5,0.4865137452549983,0.46351208759492557,0.488740328770113,0.0,4,0.4979917109012604,0.41997379064559937,0.5235475301742554,1.0,0.0
Economics1804.05785,arXiv:1804.05785,Estimating Dynamic Treatment Effects in Event Studies With Heterogeneous Treatment Effects,llama3.1,20250920_110438_graph_neural_networks_for_heterogeneous_treatment_.json,graph neural networks for heterogeneous treatment effects with staggered adoption,1,0.4865137452549983,0.4865137452549983,0.4865137452549983,0.0,1,0.0,0.0,0.0,1.0,0.0
GNNExplaine1903.03894,arXiv:1903.03894,GNNExplainer: Generating Explanations for Graph Neural Networks,llama3.1,20250920_110938_graph_neural_networks_explainability_limitations.json,graph neural networks explainability limitations,5,0.5554331883946798,0.49338777079063956,0.582866423364798,0.0,5,0.7517848610877991,0.6734243631362915,0.8240211009979248,0.0,0.0
GNNExplaine1903.03894,arXiv:1903.03894,GNNExplainer: Generating Explanations for Graph Neural Networks,llama3.1,20250920_111203_Graph_Neural_Networks_AND_cognitive_architectures_.json,Graph Neural Networks AND cognitive architectures AND human reasoning,5,0.49307348334952283,0.47184582423347965,0.5153938011081017,0.0,4,0.46285033226013184,0.24459117650985718,0.4771575927734375,1.0,0.0
GNNExplaine1903.03894,arXiv:1903.03894,GNNExplainer: Generating Explanations for Graph Neural Networks,llama3.1,20250920_111438_Graph_Neural_Networks_knowledge_graph_embedding_mu.json,Graph Neural Networks + knowledge graph embedding + multimodal learning,5,0.49383361457327524,0.4922536780348208,0.5349915829578119,0.0,5,0.5577313303947449,0.42190447449684143,0.6359719038009644,0.4,0.0
GNNExplaine1903.03894,arXiv:1903.03894,GNNExplainer: Generating Explanations for Graph Neural Networks,llama3.1,20250920_111652_Graph_Neural_Network_Neurosymbolic_Learning.json,Graph Neural Network + Neurosymbolic Learning,5,0.5289940699630784,0.49448996293516445,0.5655816653875603,0.0,3,0.5695289373397827,0.45462867617607117,0.5996114015579224,0.3333333333333333,0.0
GNNExplaine1903.03894,arXiv:1903.03894,GNNExplainer: Generating Explanations for Graph Neural Networks,llama3.1,20250920_111907_graph_neural_networks_adversarial_robustness_expla.json,graph neural networks + adversarial robustness + explainability,5,0.5229225886535392,0.49374431139554986,0.5856303613943398,0.0,3,0.5721677541732788,0.4754142165184021,0.6362020969390869,0.3333333333333333,0.0
Gaussian1502.01366,arXiv:1502.01366,Gaussian approximation potentials: A brief tutorial introduction,llama3.1,20250919_115537_Gaussian_Process_Regression_for_materials_science_.json,Gaussian Process Regression for materials science with symmetry-aware descriptors,1,0.30051829315137474,0.30051829315137474,0.30051829315137474,0.0,1,0.0,0.0,0.0,1.0,0.0
Gaussian1502.01366,arXiv:1502.01366,Gaussian approximation potentials: A brief tutorial introduction,llama3.1,20250919_115546_machine_learning_for_materials_science_with_symmet.json,machine learning for materials science with symmetry-aware descriptors and gaussian process regression,1,0.30051829315137474,0.30051829315137474,0.30051829315137474,0.0,1,0.0,0.0,0.0,1.0,0.0
Gaussian1502.01366,arXiv:1502.01366,Gaussian approximation potentials: A brief tutorial introduction,llama3.1,20250919_115701_Gaussian_process_regression_for_materials_science_.json,Gaussian process regression for materials science with symmetry-aware descriptors and transfer learning,1,0.30051829315137474,0.30051829315137474,0.30051829315137474,0.0,1,0.0,0.0,0.0,1.0,0.0
Gaussian1502.01366,arXiv:1502.01366,Gaussian approximation potentials: A brief tutorial introduction,llama3.1,20250919_115812_Gaussian_process_regression_for_materials_science_.json,Gaussian process regression for materials science with uncertainty quantification,5,0.40103211783488496,0.30051829315137474,0.42835830762345495,0.0,5,0.48491907119750977,0.3633817434310913,0.637968122959137,0.6,0.0
Gaussian1502.01366,arXiv:1502.01366,Gaussian approximation potentials: A brief tutorial introduction,llama3.1,20250919_115834_uncertainty_quantification_in_machine_learning_for.json,uncertainty quantification in machine learning for materials science with limited data,5,0.37182483946892986,0.30020082913183244,0.45023845206958135,0.0,3,0.48491907119750977,0.28316807746887207,0.5800676345825195,0.6666666666666666,0.0
Gaussian1502.01366,arXiv:1502.01366,Gaussian approximation potentials: A brief tutorial introduction,llama3.1,20250919_120030_machine_learning_interpretability_for_materials_sc.json,machine learning interpretability for materials science,5,0.33284471688571104,0.3038339660569967,0.4493074038746375,0.0,5,0.4870443344116211,0.3340144157409668,0.49447840452194214,1.0,0.0
Gaussian1502.01366,arXiv:1502.01366,Gaussian approximation potentials: A brief tutorial introduction,llama3.1,20250919_120229_generative_models_for_materials_science_structure_.json,generative models for materials science + structure prediction + molecular dynamics,5,0.47078353714963905,0.2978094797710399,0.48188734393920596,0.0,5,0.42557939887046814,0.39140135049819946,0.4958723187446594,1.0,0.0
Gaussian1502.01366,arXiv:1502.01366,Gaussian approximation potentials: A brief tutorial introduction,llama3.1,20250919_120315_graph_neural_networks_for_molecular_property_predi.json,graph neural networks for molecular property prediction with limited data,5,0.41500896075734384,0.30406221706250147,0.46375603023357154,0.0,5,0.391051322221756,0.3216283917427063,0.4274599850177765,1.0,0.0
ReAct2210.03629,arXiv:2210.03629,ReAct: Synergizing Reasoning and Acting in Language Models,llama3.1,20250919_124105_interactive_reinforcement_learning_with_large_lang.json,interactive reinforcement learning with large language models and embodied cognition,1,0.7061073360757251,0.7061073360757251,0.7061073360757251,0.0,1,0.01729544997215271,0.01729544997215271,0.01729544997215271,1.0,0.0
ReAct2210.03629,arXiv:2210.03629,ReAct: Synergizing Reasoning and Acting in Language Models,llama3.1,20250919_124114_embodied_cognition_in_large_language_models_for_de.json,embodied cognition in large language models for decision-making and control,4,0.7055870287324602,0.7027452203924331,0.7061010738540995,0.0,0,,,,,
ReAct2210.03629,arXiv:2210.03629,ReAct: Synergizing Reasoning and Acting in Language Models,llama3.1,20250919_124234_neural-symbolic_integration_for_explainable_decisi.json,neural-symbolic integration for explainable decision-making,5,0.6734903318281131,0.6577118139109337,0.7061385535314861,0.0,5,0.38859713077545166,0.22443562746047974,0.47575798630714417,1.0,0.0
ReAct2210.03629,arXiv:2210.03629,ReAct: Synergizing Reasoning and Acting in Language Models,llama3.1,20250919_124502_adversarial_attacks_on_embodied_language_models.json,adversarial attacks on embodied language models,5,0.7126888743576851,0.6963235332141788,0.7472293345379705,0.0,4,0.3825252652168274,0.2827264070510864,0.4917733371257782,1.0,0.0
ReAct2210.03629,arXiv:2210.03629,ReAct: Synergizing Reasoning and Acting in Language Models,llama3.1,20250919_124733_neural-symbolic_integration_for_creative_problem-s.json,neural-symbolic integration for creative problem-solving in language models,2,0.7061010738540995,0.7057283360268372,0.7061010738540995,0.0,0,,,,,
ReAct2210.03629,arXiv:2210.03629,ReAct: Synergizing Reasoning and Acting in Language Models,llama3.1,20250919_124807_neural-symbolic_integration_for_creative_problem-s.json,neural-symbolic integration for creative problem-solving in language models,2,0.7061010738540995,0.7057283360268372,0.7061010738540995,0.0,0,,,,,
Self-Consistency2203.11171,arXiv:2203.11171,Self-Consistency Improves Chain of Thought Reasoning in Language Models,llama3.1,20250919_124938_chain-of-thought_prompting_self-consistency_reason.json,"chain-of-thought prompting, self-consistency, reasoning in LLMs, decoding strategies, few-shot learning",1,0.6597734680654028,0.6597734680654028,0.6597734680654028,0.0,1,0.4463774859905243,0.4463774859905243,0.4463774859905243,1.0,0.0
Self-Consistency2203.11171,arXiv:2203.11171,Self-Consistency Improves Chain of Thought Reasoning in Language Models,llama3.1,20250919_125119_adversarial_attacks_on_chain-of-thought_reasoning_.json,adversarial attacks on chain-of-thought reasoning in language models,1,0.6513061880830155,0.6513061880830155,0.6513061880830155,0.0,1,0.0,0.0,0.0,1.0,0.0
Self-Consistency2203.11171,arXiv:2203.11171,Self-Consistency Improves Chain of Thought Reasoning in Language Models,llama3.1,20250919_125246_neural-symbolic_integration_for_reasoning_in_langu.json,neural-symbolic integration for reasoning in language models,5,0.6505421292529268,0.6355287543236628,0.6513195205898703,0.0,4,0.44803768396377563,0.371232807636261,0.5958680510520935,0.75,0.0
Self-Consistency2203.11171,arXiv:2203.11171,Self-Consistency Improves Chain of Thought Reasoning in Language Models,llama3.1,20250919_125517_explaining_large_language_model_predictions_throug.json,explaining large language model predictions through concept-based analysis,5,0.6648792605254307,0.6512936694791955,0.6844415338948157,0.0,4,0.43036752939224243,0.3337227702140808,0.4764680564403534,1.0,0.0
Self-Consistency2203.11171,arXiv:2203.11171,Self-Consistency Improves Chain of Thought Reasoning in Language Models,llama3.1,20250919_125732_emergence_of_reasoning_paths_in_large_language_mod.json,emergence of reasoning paths in large language models,5,0.7014797071114224,0.6865561489950815,0.7591721438587606,0.0,5,0.427883118391037,0.3289063274860382,0.704559326171875,0.8,0.0
Self-RAG2310.11511,arXiv:2310.11511,"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",llama3.1,20250923_094556_retrieval-augmented_generation_self-reflection_fac.json,retrieval-augmented generation self-reflection factuality citation accuracy,5,0.7643437137346567,0.7508334298250068,1.0,0.0,4,0.7837510108947754,0.666630208492279,1.0,0.0,0.0
Self-RAG2310.11511,arXiv:2310.11511,"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",llama3.1,20250923_094741_retrieval-augmented_generation_with_self-reflectio.json,retrieval-augmented generation with self-reflection and controllable decoding,1,0.7502473018552451,0.7502473018552451,0.7502473018552451,0.0,1,0.009166449308395386,0.009166449308395386,0.009166449308395386,1.0,0.0
Self-RAG2310.11511,arXiv:2310.11511,"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",llama3.1,20250923_094907_meta-learning_for_adaptive_retrieval-augmented_gen.json,meta-learning for adaptive retrieval-augmented generation,5,0.7558903839748585,0.734235708518115,0.787700573138377,0.0,5,0.5658551454544067,0.5258505344390869,0.6724076867103577,0.2,0.0
Self-RAG2310.11511,arXiv:2310.11511,"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",llama3.1,20250923_095118_adversarial_training_for_retrieval-augmented_gener.json,adversarial training for retrieval-augmented generation,5,0.7434061044234448,0.7281453883791277,0.7502473018552451,0.0,5,0.5918297171592712,0.4049232602119446,0.6832611560821533,0.2,0.0
Self-RAG2310.11511,arXiv:2310.11511,"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection",llama3.1,20250923_095352_neural-symbolic_learning_for_interpretable_retriev.json,neural-symbolic learning for interpretable retrieval-augmented generation,5,0.7503013606901551,0.730222419728732,0.792252974292328,0.0,5,0.5255099534988403,0.36172759532928467,0.6417629718780518,0.8,0.0
Toolformer2302.04761,arXiv:2302.04761,Toolformer: Language Models Can Teach Themselves to Use Tools,llama3.1,20250919_133352_self-supervised_learning_of_API_usage_in_language_.json,self-supervised learning of API usage in language models,2,0.6887499318319612,0.6731834595364135,0.6887499318319612,0.0,2,0.6370370388031006,0.5936058759689331,0.6370370388031006,0.0,0.0
Toolformer2302.04761,arXiv:2302.04761,Toolformer: Language Models Can Teach Themselves to Use Tools,llama3.1,20250919_133541_language_models_interactive_learning_embodied_cogn.json,language models interactive learning embodied cognition,5,0.6512442162400529,0.634724142044477,0.6783386254918746,0.0,4,0.536690890789032,0.4346078336238861,0.6098105311393738,0.75,0.0
Toolformer2302.04761,arXiv:2302.04761,Toolformer: Language Models Can Teach Themselves to Use Tools,llama3.1,20250919_133743_meta-learning_for_adaptive_api_usage_in_language_m.json,meta-learning for adaptive api usage in language models,1,0.634498472055565,0.634498472055565,0.634498472055565,0.0,1,0.0,0.0,0.0,1.0,0.0
Toolformer2302.04761,arXiv:2302.04761,Toolformer: Language Models Can Teach Themselves to Use Tools,llama3.1,20250919_133915_language_models_for_automated_theorem_proving_and_.json,language models for automated theorem proving and mathematical discovery,5,0.6263165598093892,0.6124461926136178,0.6345091164313303,0.0,3,0.4569648802280426,0.41499197483062744,0.4705296456813812,1.0,0.0
Toolformer2302.04761,arXiv:2302.04761,Toolformer: Language Models Can Teach Themselves to Use Tools,llama3.1,20250919_134154_language_models_as_cognitive_architectures_for_art.json,language models as cognitive architectures for artificial general intelligence,5,0.634494357400652,0.5719072405505392,0.6651876430865673,0.0,5,0.3915257155895233,0.3055245578289032,0.5162326097488403,1.0,0.0
Tree-of-Thoughts2305.10601,arXiv:2305.10601,Tree of Thoughts: Deliberate Problem Solving with Large Language Models,llama3.1,20250919_134506_language_models_reasoning_search_planning_tree_exp.json,language models reasoning search planning tree exploration,5,0.695101804906412,0.6760257049147889,0.7467619662659071,0.0,5,0.6760451793670654,0.5831857919692993,0.7330629229545593,0.0,0.0
Tree-of-Thoughts2305.10601,arXiv:2305.10601,Tree of Thoughts: Deliberate Problem Solving with Large Language Models,llama3.1,20250919_134853_meta-learning_for_large_language_models_with_cogni.json,meta-learning for large language models with cognitive architectures,5,0.6550481753164935,0.6540106364541902,0.6559954403239635,0.0,1,0.41513127088546753,0.41513127088546753,0.41513127088546753,1.0,0.0
Tree-of-Thoughts2305.10601,arXiv:2305.10601,Tree of Thoughts: Deliberate Problem Solving with Large Language Models,llama3.1,20250919_135129_meta-learning_for_large_language_models_with_cogni.json,meta-learning for large language models with cognitive architectures,5,0.6550481753164935,0.6540106364541902,0.6559954403239635,0.0,1,0.41513127088546753,0.41513127088546753,0.41513127088546753,1.0,0.0
Tree-of-Thoughts2305.10601,arXiv:2305.10601,Tree of Thoughts: Deliberate Problem Solving with Large Language Models,llama3.1,20250919_135405_meta-learning_for_large_language_models_with_cogni.json,meta-learning for large language models with cognitive architectures,5,0.6550481753164935,0.6540106364541902,0.6559954403239635,0.0,1,0.41513127088546753,0.41513127088546753,0.41513127088546753,1.0,0.0
