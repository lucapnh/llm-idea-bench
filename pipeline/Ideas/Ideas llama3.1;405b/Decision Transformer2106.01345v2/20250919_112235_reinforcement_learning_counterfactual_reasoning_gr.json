{
    "query": "reinforcement learning + counterfactual reasoning + graph neural networks",
    "result": {
        "1": "Learning and Evaluating Graph Neural Network Explanations based on Counterfactual and Factual Reasoning. Juntao Tan, Shijie Geng, Zuohui Fu, Yingqiang Ge, Shuyuan Xu, Yunqi Li, Yongfeng Zhang. The Web Conference, 2022.\nNumber of citations: 125\nAbstract: Structural data well exists in Web applications, such as social networks in social media, citation networks in academic websites, and threads data in online forums. Due to the complex topology, it is difficult to process and make use of the rich information within such data. Graph Neural Networks (GNNs) have shown great advantages on learning representations for structural data. However, the non-transparency of the deep learning models makes it non-trivial to explain and interpret the predictions made by GNNs. Meanwhile, it is also a big challenge to evaluate the GNN explanations, since in many cases, the ground-truth explanations are unavailable. In this paper, we take insights of Counterfactual and Factual (CF2) reasoning from causal inference theory, to solve both the learning and evaluation problems in explainable GNNs. For generating explanations, we propose a model-agnostic framework by formulating an optimization problem based on both of the two casual perspectives. This distinguishes CF2 from previous explainable GNNs that only consider one of them. Another contribution of the work is the evaluation of GNN explanations. For quantitatively evaluating the generated explanations without the requirement of ground-truth, we design metrics based on Counterfactual and Factual reasoning to evaluate the necessity and sufficiency of the explanations. Experiments show that no matter ground-truth explanations are available or not, CF2 generates better explanations than previous state-of-the-art methods on real-world datasets. Moreover, the statistic analysis justifies the correlation between the performance on ground-truth evaluation and our proposed metrics.",
        "2": "Graph Neural Networks and Deep Reinforcement Learning-Based Resource Allocation for V2X Communications. Maoxin Ji, Qiong Wu, Pingyi Fan, Nan Cheng, Wen Chen, Jiangzhou Wang, K. Letaief. IEEE Internet of Things Journal, 2024.\nNumber of citations: 42\nAbstract: In the rapidly evolving landscape of Internet of Vehicles (IoV) technology, cellular vehicle-to-everything (C-V2X) communication has attracted much attention due to its superior performance in coverage, latency, and throughput. Resource allocation within C-V2X is crucial for ensuring the transmission of safety information and meeting the stringent requirements for ultralow latency and high reliability in vehicle-to-vehicle (V2V) communication. This article proposes a method that integrates graph neural networks (GNNs) with deep reinforcement learning (DRL) to address this challenge. By constructing a dynamic graph with communication links as nodes and employing the graph sample and aggregation (GraphSAGE) model to adapt to changes in graph structure, the model aims to ensure a high success rate for V2V communication while minimizing interference on vehicle-to-infrastructure (V2I) links, thereby ensuring the successful transmission of V2V link information and maintaining high transmission rates for V2I links. The proposed method retains the global feature learning capabilities of GNN and supports distributed network deployment, allowing vehicles to extract low-dimensional features that include structural information from the graph network based on local observations and to make independent resource allocation decisions. Simulation results indicate that the introduction of GNN, with a modest increase in computational load, effectively enhances the decision-making quality of agents, demonstrating superiority to other methods. This study not only provides a theoretically efficient resource allocation strategy for V2V and V2I communications but also paves a new technical path for resource management in practical IoV environments.",
        "3": "Dynamic Fraud Detection: Integrating Reinforcement Learning into Graph Neural Networks. Yuxin Dong, Jianhua Yao, Jiajing Wang, Yingbin Liang, Shuhan Liao, Minheng Xiao. 2024 6th International Conference on Data-driven Optimization of Complex Systems (DOCS), 2024.\nNumber of citations: 23\nAbstract: Financial fraud refers to the act of obtaining financial benefits through dishonest means. Such behavior not only disrupts the order of the financial market but also harms economic and social development and breeds other illegal and criminal activities. With the popularization of the internet and online payment methods, many fraudulent activities and money laundering behaviors in life have shifted from offline to online, posing a great challenge to regulatory authorities. How to efficiently detect these financial fraud activities has become an urgent issue that needs to be resolved. Graph neural networks are a type of deep learning model that can utilize the interactive relationships within graph structures, and they have been widely applied in the field of fraud detection. However, there are still some issues. First, fraudulent activities only account for a very small part of transaction transfers, leading to an inevitable problem of label imbalance in fraud detection. At the same time, fraudsters often disguise their behavior, which can have a negative impact on the final prediction results. In addition, existing research has overlooked the importance of balancing neighbor information and central node information. For example, when the central node has too many neighbors, the features of the central node itself are often neglected. Finally, fraud activities and patterns are constantly changing over time, so considering the dynamic evolution of graph edge relationships is also very important.",
        "4": "Graph Neural Networks for Vulnerability Detection: A Counterfactual Explanation. Zhaoyang Chu, Yao Wan, Qian Li, Yang Wu, Hongyu Zhang, Yulei Sui, Guandong Xu, Hai Jin. International Symposium on Software Testing and Analysis, 2024.\nNumber of citations: 19\nAbstract: Vulnerability detection is crucial for ensuring the security and reliability of software systems. Recently, Graph Neural Networks (GNNs) have emerged as a prominent code embedding approach for vulnerability detection, owing to their ability to capture the underlying semantic structure of source code. However, GNNs face significant challenges in explainability due to their inherently black-box nature. To this end, several factual reasoning-based explainers have been proposed. These explainers provide explanations for the predictions made by GNNs by analyzing the key features that contribute to the outcomes. We argue that these factual reasoning-based explanations cannot answer critical what-if questions: \"What would happen to the GNN's decision if we were to alter the code graph into alternative structures?\" Inspired by advancements of counterfactual reasoning in artificial intelligence, we propose CFExplainer, a novel counterfactual explainer for GNN-based vulnerability detection. Unlike factual reasoning-based explainers, CFExplainer seeks the minimal perturbation to the input code graph that leads to a change in the prediction, thereby addressing the what-if questions for vulnerability detection. We term this perturbation a counterfactual explanation, which can pinpoint the root causes of the detected vulnerability and furnish valuable insights for developers to undertake appropriate actions for fixing the vulnerability. Extensive experiments on four GNN-based vulnerability detection models demonstrate the effectiveness of CFExplainer over existing state-of-the-art factual reasoning-based explainers.",
        "5": "A Survey of Intelligent End-to-End Networking Solutions: Integrating Graph Neural Networks and Deep Reinforcement Learning Approaches. Prohim Tam, Seyha Ros, Inseok Song, S. Kang, Seokhoon Kim. Electronics, 2024.\nNumber of citations: 14\nAbstract: This paper provides a comprehensive survey of the integration of graph neural networks (GNN) and deep reinforcement learning (DRL) in end-to-end (E2E) networking solutions. We delve into the fundamentals of GNN, its variants, and the state-of-the-art applications in communication networking, which reveal the potential to revolutionize access, transport, and core network management policies. This paper further explores DRL capabilities, its variants, and the trending applications in E2E networking, particularly in enhancing dynamic network (re)configurations and resource management. By fusing GNN with DRL, we spotlight novel approaches, ranging from radio access networks to core management and orchestration, across E2E network layers. Deployment scenarios in smart transportation, smart factory, and smart grids demonstrate the practical implications of our survey topic. Lastly, we point out potential challenges and future research directions, including the critical aspects for modelling explainability, the reduction in overhead consumption, interoperability with existing schemes, and the importance of reproducibility. Our survey aims to serve as a roadmap for future developments in E2E networking, guiding through the current landscape, challenges, and prospective breakthroughs in the algorithm modelling toward network automation using GNN and DRL.",
        "6": "Game-theoretic Counterfactual Explanation for Graph Neural Networks. Chirag Chhablani, Sarthak Jain, Akshay Channesh, Ian A. Kash, Sourav Medya. The Web Conference, 2024.\nNumber of citations: 8\nAbstract: Graph Neural Networks (GNNs) have been a powerful tool for node classification tasks in complex networks. However, their decision-making processes remain a black-box to users, making it challenging to understand the reasoning behind their predictions. Counterfactual explanations (CFE) have shown promise in enhancing the interpretability of machine learning models. Prior approaches to compute CFE for GNNS often are learning-based approaches that require training additional graphs. In this paper, we propose a semivalue-based, non-learning approach to generate CFE for node classification tasks, eliminating the need for any additional training. Our results reveals that computing Banzhaf values requires lower sample complexity in identifying the counterfactual explanations compared to other popular methods such as computing Shapley values. Our empirical evidence indicates computing Banzhaf values can achieve up to a fourfold speed up compared to Shapley values. We also design a thresholding method for computing Banzhaf values and show theoretical and empirical results on its robustness in noisy environments, making it superior to Shapley values. Furthermore, the thresholded Banzhaf values are shown to enhance efficiency without compromising the quality (i.e., fidelity) in the explanations in three popular graph datasets.",
        "7": "Leveraging Graph Neural Networks and Multi-Agent Reinforcement Learning for Inventory Control in Supply Chains. Niki Kotecha, Antonio del Rio-Chanona. arXiv.org, 2024.\nNumber of citations: 4\nAbstract: Inventory control in modern supply chains has attracted significant attention due to the increasing number of disruptive shocks and the challenges posed by complex dynamics, uncertainties, and limited collaboration. Traditional methods, which often rely on static parameters, struggle to adapt to changing environments. This paper proposes a Multi-Agent Reinforcement Learning (MARL) framework with Graph Neural Networks (GNNs) for state representation to address these limitations. Our approach redefines the action space by parameterizing heuristic inventory control policies, making it adaptive as the parameters dynamically adjust based on system conditions. By leveraging the inherent graph structure of supply chains, our framework enables agents to learn the system's topology, and we employ a centralized learning, decentralized execution scheme that allows agents to learn collaboratively while overcoming information-sharing constraints. Additionally, we incorporate global mean pooling and regularization techniques to enhance performance. We test the capabilities of our proposed approach on four different supply chain configurations and conduct a sensitivity analysis. This work paves the way for utilizing MARL-GNN frameworks to improve inventory management in complex, decentralized supply chain environments.",
        "8": "Efficient Integration of Reinforcement Learning in Graph Neural Networks-Based Recommender Systems. Abdurakhmon Sharifbaev, Mikhail Mozikov, Hakimjon Zaynidinov, Ilya Makarov. IEEE Access, 2024.\nNumber of citations: 3\nAbstract: Recommendation systems have advanced significantly in recent years, achieving greater accuracy and relevance. However, traditional approaches often suffer from a mismatch between the losses used during training and the metrics used for evaluation. Models are typically trained to minimize a loss function, while their effectiveness during testing is assessed using different ranking metrics, leading to suboptimal recommendation quality. To address this limitation, reinforcement learning (RL) has emerged as a promising solution. Although RL has been applied in recommendation systems, the integration of graph neural networks (GNNs) within this framework remains underexplored. In this study, we bridge this gap by integrating GNNs and RL to enhance ranking accuracy and recommendation quality. We propose two key innovations: 1) leveraging learnable graphs to embed user-item interactions, with RL optimizing user rewards to improve ranking quality, and 2) modifying GNN architectures with skip connections to enhance recommendation accuracy while reducing training time and improving convergence. Our comprehensive analysis on multiple real-world datasets demonstrates the impact of different GNN architectures and their modifications on the effectiveness of recommendation systems. Our findings demonstrate the potential of combining GNNs and RL to overcome the limitations of traditional recommendation models and achieve state-of-the-art performance, with XSimGCL-skip achieving an average improvement of approximately 2.5% over baseline methods.",
        "9": "Learning Counterfactual Explanation of Graph Neural Networks via Generative Flow Network. Kangjia He, Li Liu, Youmin Zhang, Ye Wang, Qun Liu, Guoyin Wang. IEEE Transactions on Artificial Intelligence, 2024.\nNumber of citations: 2\nAbstract: Counterfactual subgraphs explain graph neural networks (GNNs) by answering the question: \u201cHow would the prediction change if a certain subgraph were absent in the input instance?\u201d The differentiable proxy adjacency matrix is prevalent in current counterfactual subgraph discovery studies due to its ability to avoid exhaustive edge searching. However, a prediction gap exists when feeding the proxy matrix with continuous values and the thresholded discrete adjacency matrix to GNNs, compromising the optimization of the subgraph generator. Furthermore, the end-to-end learning schema adopted in the subgraph generator limits the diversity of counterfactual subgraphs. To this end, we propose CF-GFNExplainer, a flow-based approach for learning counterfactual subgraphs. CF-GFNExplainer employs a policy network with a discrete edge removal schema to construct counterfactual subgraph generation trajectories. Additionally, we introduce a loss function designed to guide CF-GFNExplainer's optimization. The discrete adjacency matrix generated in each trajectory eliminates the prediction gap, enhancing the validity of the learned subgraphs. Furthermore, the multitrajectories sampling strategy adopted in CF-GFNExplainer results in diverse counterfactual subgraphs. Extensive experiments conducted on synthetic and real-world datasets demonstrate the effectiveness of the proposed method in terms of validity and diversity.",
        "10": "GCFExplainer: Global Counterfactual Explainer for Graph Neural Networks. Mert Kosan, Zexi Huang, Sourav Medya, Sayan Ranu, Ambuj Singh. ACM Transactions on Intelligent Systems and Technology, 2024.\nNumber of citations: 1\nAbstract: Graph neural networks (GNNs) find applications in various domains such as computational biology, natural language processing, and computer security. Owing to their popularity, there is an increasing need to explain GNN predictions since GNNs are black-box machine learning models. One way to address this issue involves using counterfactual reasoning where the objective is to alter the GNN prediction by minimal changes in the input graph. Existing methods for counterfactual explanation of GNNs are limited to instance-specific local reasoning. This approach has two major limitations of not being able to offer global recourse policies and overloading human cognitive ability with too much information. In this work, we study the global explainability of GNNs through global counterfactual reasoning. Specifically, we want to find a small set of representative counterfactual graphs that explains all input graphs. Towards this goal, we propose GCFExplainer, a novel algorithm powered by vertex-reinforced random walks on an edit map of graphs with a greedy summary. Extensive experiments on real graph datasets show that the global explanation from GCFExplainer provides important high-level insights of the model behavior and achieves a 46.9% gain in recourse coverage, a 9.5% reduction in recourse cost compared to the state-of-the-art local counterfactual explainers. We also demonstrate that GCFExplainer generates explanations that are more consistent with input dataset characteristics, and is robust under adversarial attacks. In addition, K-GCFExplainer, which incorporates a graph clustering component into GCFExplainer, is introduced as a more competitive extension for datasets with a clustering structure, leading to superior performance in three out of four datasets in the experiments and better scalability."
    }
}