{
    "query": "reinforcement learning with cognitive architectures and neural-symbolic integration",
    "result": {
        "1": "Hybrid Neural Systems. Stefan Wermter, Ron Sun. Lecture Notes in Computer Science, 1998.\nNumber of citations: 60\nAbstract: None",
        "2": "Sequence Learning - Paradigms, Algorithms, and Applications. . , 2001.\nNumber of citations: 47\nAbstract: None",
        "3": "Sequence Learning - Paradigms, Algorithms, and Applications. Ron Sun, C. L. Giles. , 2001.\nNumber of citations: 42\nAbstract: None",
        "4": "NOVAMENTE: An Integrative Architecture for Artificial General Intelligence. B. Goertzel, C. Pennachin, Andre Senna, Thiago Turchetti Maia, Gui Lamacie. , 2004.\nNumber of citations: 27\nAbstract: None",
        "5": "Adaptive human-robot teaming through integrated symbolic and subsymbolic artificial intelligence: preliminary results. D. Handelman, Corban G. Rivera, R. St. Amant, Emma A. Holmes, Andrew R. Badger, Bryanna Y. Yeh. Defense + Commercial Sensing, 2022.\nNumber of citations: 7\nAbstract: As the autonomy of intelligent systems continues to increase, the ability of humans to maintain control over machine behavior, work effectively in concert with them, and trust them, becomes paramount. Ideally, a machine\u2019s plan of action would be accessible to and understandable by human team members, and machine behavior would be modifiable in real time, in the field, to accommodate unanticipated situations. The ability of machines to adapt to new situations quickly and reliably based on both human input and autonomous learning has the potential to enhance numerous human-machine teaming scenarios. Our research focuses on the question, \u201cCan robots become competent and adaptive teammates by emulating human skill acquisition strategies?\u201d In this paper we describe the Robotic Skill Acquisition (RSA) cognitive architecture and show preliminary results of teaming experiments involving a human wearing an augmented reality headset and a quadruped robot performing tasks related to reconnaissance. The goal is to combine instruction and discovery by integrating declarative symbolic AI and reflexive neural network learning to produce robust, explainable and trusted robot behavior, adjustable autonomy, and adaptive human-robot teaming. Humans and robots start with a playbook of modifiable hierarchical task descriptions that encode explicit task knowledge. Neural network based feedback error learning enables human-directed behavior shaping, and reinforcement learning enables discovery of novel subtask control strategies. It is anticipated that modifications to and transitions between symbolic and subsymbolic processing will enable highly adaptive behavior in support of enhanced situational awareness and operational effectiveness of human-robot teams.",
        "6": "Emergence of Belief Systems and the Future of Artificial Intelligence. Howard Schneider. Biologically Inspired Cognitive Architectures, 2019.\nNumber of citations: 3\nAbstract: None",
        "7": "Benefits of combining dimensional attention and working memory for partially observable reinforcement learning problems. Ngozi Omatu, Joshua L. Phillips. ACM Southeast Conference, 2021.\nNumber of citations: 0\nAbstract: Neuroscience provides a rich source of inspiration for new types of algorithms and architectures to employ when building AI and the resulting biologically-plausible approaches that provide formal, testable models of brain function. The working memory toolkit (WMtk), was developed to assist the integration of an artificial neural network (ANN)-based computational neuroscience model of working memory into reinforcement learning (RL) agents, mitigating the details of ANN design and providing a simple symbolic encoding interface. While the WMtk allows RL agents to perform well in partially-observable domains, it requires prefiltering of sensory information by the programmer: a task often delegated to dimensional attention mechanisms in other cognitive architectures. To fill this gap, we develop and test a biologically-plausible dimensional attention filter for the WMtk and validate model performance using a partially-observable 1D maze task. We show that the attention filter improves learning behavior in two ways by: 1) speeding up learning in the short-term, early in training and 2) developing emergent alternative strategies which optimize performance over the long-term.",
        "8": "Neural Cognitive Architectures for Never-Ending Learning. Emmanouil Antonios Platanios, Tom M. Mitchell, Eric Horvitz, R. Caruana, Graham Neubig. , 2019.\nNumber of citations: 0\nAbstract: None",
        "9": "Workshop proposal: Deep Learning in Computational Cognitive Science. Ilker Yildirim, J. Tenenbaum. Annual Meeting of the Cognitive Science Society, 2017.\nNumber of citations: 0\nAbstract: None",
        "10": "Multimodal Learning of Actions with Deep Neural Network Self-Organization. G. I. Parisi. , 2017.\nNumber of citations: 0\nAbstract: None"
    }
}