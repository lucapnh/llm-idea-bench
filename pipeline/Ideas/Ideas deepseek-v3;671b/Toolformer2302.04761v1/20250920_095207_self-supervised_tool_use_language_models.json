{
    "query": "self-supervised tool use language models",
    "result": {
        "1": "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations. Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut. International Conference on Learning Representations, 2019.\nNumber of citations: 6623\nAbstract: Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems, we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and \\squad benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at this https URL.",
        "2": "ToRL: Scaling Tool-Integrated RL. Xuefeng Li, Haoyang Zou, Pengfei Liu. arXiv.org, 2025.\nNumber of citations: 35\nAbstract: We introduce ToRL (Tool-Integrated Reinforcement Learning), a framework for training large language models (LLMs) to autonomously use computational tools via reinforcement learning. Unlike supervised fine-tuning, ToRL allows models to explore and discover optimal strategies for tool use. Experiments with Qwen2.5-Math models show significant improvements: ToRL-7B reaches 43.3\\% accuracy on AIME~24, surpassing reinforcement learning without tool integration by 14\\% and the best existing Tool-Integrated Reasoning (TIR) model by 17\\%. Further analysis reveals emergent behaviors such as strategic tool invocation, self-regulation of ineffective code, and dynamic adaptation between computational and analytical reasoning, all arising purely through reward-driven learning.",
        "3": "SMART: Self-Aware Agent for Tool Overuse Mitigation. Cheng Qian, Emre Can Acikgoz, Hongru Wang, Xiusi Chen, Avirup Sil, Dilek Hakkani-Tur, Gokhan Tur, Heng Ji. Annual Meeting of the Association for Computational Linguistics, 2025.\nNumber of citations: 15\nAbstract: Current Large Language Model (LLM) agents demonstrate strong reasoning and tool use capabilities, but often lack self-awareness, failing to balance these approaches effectively. This imbalance leads to Tool Overuse, where models unnecessarily rely on external tools for tasks solvable with parametric knowledge, increasing computational overhead. Inspired by human metacognition, we introduce SMART (Strategic Model-Aware Reasoning with Tools), a paradigm that enhances an agent's self-awareness to optimize task handling and reduce tool overuse. To support this paradigm, we introduce SMART-ER, a dataset spanning three domains, where reasoning alternates between parametric knowledge and tool-dependent steps, with each step enriched by rationales explaining when tools are necessary. Through supervised training, we develop SMARTAgent, a family of models that dynamically balance parametric knowledge and tool use. Evaluations show that SMARTAgent reduces tool use by 24% while improving performance by over 37%, enabling 7B-scale models to match its 70B counterpart and GPT-4o. Additionally, SMARTAgent generalizes to out-of-distribution test data like GSM8K and MINTQA, maintaining accuracy with just one-fifth the tool calls. These highlight the potential of strategic tool use to enhance reasoning, mitigate overuse, and bridge the gap between model size and performance, advancing intelligent and resource-efficient agent designs.",
        "4": "Practical Sentiment Analysis for Education: The Power of Student Crowdsourcing. Robert Kasumba, Marion Neumman. AAAI Conference on Artificial Intelligence, 2024.\nNumber of citations: 6\nAbstract: Sentiment analysis provides a promising tool to automatically assess the emotions voiced in written student feedback such as periodically collected unit-of-study reflections. The commonly used dictionary-based approaches are limited to major languages and fail to capture contextual differences. Pretrained large language models have been shown to be biased and online versions raise privacy concerns. Hence, we resort to traditional supervised machine learning (ML) approaches which are designed to overcome these issues by learning from domain-specific labeled data. However, these labels are hard to come by -- in our case manually annotating student feedback is prone to bias and time-consuming, especially in high-enrollment courses. In this work, we investigate the use of student crowdsourced labels for supervised sentiment analysis for education. Specifically, we compare crowdsourced and student self-reported labels with human expert annotations and use them in various ML approaches to evaluate the performance on predicting emotions of written student feedback collected from large computer science classes. We find that the random forest model trained with student-crowdsourced labels tremendously improves the identification of reflections with negative sentiment. In addition to our quantitative study, we describe our crowdsourcing experiment which was intentionally designed to be an educational activity in an introduction to data science course.",
        "5": "Self-Training Large Language Models for Tool-Use Without Demonstrations. Ne Luo, Aryo Pradipta Gema, Xuanli He, Emile van Krieken, Pietro Lesci, Pasquale Minervini. North American Chapter of the Association for Computational Linguistics, 2025.\nNumber of citations: 4\nAbstract: Large language models (LLMs) remain prone to factual inaccuracies and computational errors, including hallucinations and mistakes in mathematical reasoning. Recent work augmented LLMs with tools to mitigate these shortcomings, but often requires curated gold tool-use demonstrations. In this paper, we investigate whether LLMs can learn to use tools without demonstrations. First, we analyse zero-shot prompting strategies to guide LLMs in tool utilisation. Second, we propose a self-training method to synthesise tool-use traces using the LLM itself. We compare supervised fine-tuning and preference fine-tuning techniques for fine-tuning the model on datasets constructed using existing Question Answering (QA) datasets, i.e., TriviaQA and GSM8K. Experiments show that tool-use enhances performance on a long-tail knowledge task: 3.7% on PopQA, which is used solely for evaluation, but leads to mixed results on other datasets, i.e., TriviaQA, GSM8K, and NQ-Open. Our findings highlight the potential and challenges of integrating external tools into LLMs without demonstrations.",
        "6": "MetaTool: Facilitating Large Language Models to Master Tools with Meta-task Augmentation. Xiaohan Wang, Dian Li, Yilin Zhao, Sinbadliu, Hui Wang. arXiv.org, 2024.\nNumber of citations: 2\nAbstract: Utilizing tools with Large Language Models (LLMs) is essential for grounding AI agents in real-world applications. The prevailing approach involves few-shot prompting with demonstrations or fine-tuning with expert annotations. However, mere in-context demonstrations may fail to cover sufficient knowledge for complex tools and tasks. Training on solution paths is also hindered by the high cost of expert annotations and generalizing to new tools. A core challenge of generalizable tool use lies in understanding the\"meta\", or fundamental natures of tools that are transferable across tasks, such as causality and constraints. In this paper, we present MetaTool, a novel tool learning methodology designed to generalize across any reusable toolset. Our approach incorporates a self-supervised augmentation technique derived from a series of meta-tasks. This involves predicting masked elements in the tool execution process. The self-supervised procedure enables scalable generation of high-quality QA data, which is handy for supervising tool understanding. By incorporating meta-task data into task-oriented training, our method significantly enhances the performance of open-source LLMs, achieving results comparable to ChatGPT in both tool-based planning and chatting scenarios. Through large-scale instruction tuning, the MetaTool model demonstrates impressive zero-shot generalizability on new tasks.",
        "7": "MATATA: a weak-supervised MAthematical Tool-Assisted reasoning for Tabular Applications. Vishnou Vinayagame, Gregory Senay, Luis Mart\u00ed. arXiv.org, 2024.\nNumber of citations: 0\nAbstract: None",
        "8": "Fake Review Detection using Supervised and Semi-Supervised Learning with Natural Language Processing Techniques in Python. K. Mahesh, K. Hari Priya, K. V. S Meghana, K. Om Sai Vinay, N. Anil Chakravarthy. International Journal of Advanced Research in Science, Communication and Technology, 2023.\nNumber of citations: 0\nAbstract: This research paper explores the use of supervised and semi-supervised learning techniques along with natural language processing in Python for detecting fake reviews. The study discusses the importance of detecting fake reviews and its impact on businesses and customers. The proposed approach involves extracting relevant features from text data using various natural language processing techniques and training supervised learning models such as logistic regression, support vector machines, and random forests. Additionally, a semi-supervised learning technique called self-training is employed to improve the model's performance using unlabeled data. The effectiveness of the proposed approach is evaluated on a dataset of reviews from Amazon and Yelp, and the results show that the models achieve high accuracy in detecting fake reviews. The study concludes that the proposed approach can be a useful tool for businesses and customers to identify and filter out fake reviews.",
        "9": "\"It Listens Better Than My Therapist\": Exploring Social Media Discourse on LLMs as Mental Health Tool. Anna Haensch. arXiv.org, 2025.\nNumber of citations: 0\nAbstract: The emergence of generative AI chatbots such as ChatGPT has prompted growing public and academic interest in their role as informal mental health support tools. While early rule-based systems have been around for several years, large language models (LLMs) offer new capabilities in conversational fluency, empathy simulation, and availability. This study explores how users engage with LLMs as mental health tools by analyzing over 10,000 TikTok comments from videos referencing LLMs as mental health tools. Using a self-developed tiered coding schema and supervised classification models, we identify user experiences, attitudes, and recurring themes. Results show that nearly 20% of comments reflect personal use, with these users expressing overwhelmingly positive attitudes. Commonly cited benefits include accessibility, emotional support, and perceived therapeutic value. However, concerns around privacy, generic responses, and the lack of professional oversight remain prominent. It is important to note that the user feedback does not indicate which therapeutic framework, if any, the LLM-generated output aligns with. While the findings underscore the growing relevance of AI in everyday practices, they also highlight the urgent need for clinical and ethical scrutiny in the use of AI for mental health support.",
        "10": "Improving Automated Assessment of English Spoken Discourse Using Transfer Learning Models-Wav2Vec 2.0. N. S. Hameed, S. Vijayakumar, K. Rajaraman, V. V. Kumar, Tamilarasan P, M. Faizal. 2025 Fifth International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT), 2025.\nNumber of citations: 0\nAbstract: Automated Assessment of English Spoken Discourse is invaluable tool used in the process of learning foreign languages, teaching and communication as it is capable of delivering a large number of assessments of spoken language without significant human interferences. However, common approaches may yield some issues in terms of accuracy, methods' applicability to a variety of accents and languages, and the scalability of the techniques. Conventional techniques including HMM-GMM and contemporary DL techniques like the CNN-RNN triangulate unsatisfactory results due to the inability to capture more intricate spoken discourse since they are unable to pick tune from the din. In response to these difficulties, this research proposal presents the following framework using Wav2Vec 2.0, a self-supervised learning model involved in speech signals. The proposed method makes use of Wav2Vec 2.0 to capture rich representations directly from the raw input data to minimize dependence on labelled data and improve robustness to different patterns of speech. Applicable in Python, the model is fine-tuned in spoken discourse datasets and is assessed based on primary metrics of performance; test performance: 99.1%. These results are much better than traditional and baseline methods and clearly demonstrate the high stability and potential of the model. This way, the study that addresses prior limitations and offers a stable solution contributes to the development of the automated speech assessment. Further work that could be suggested is the selection of multimodal integration approaches and real time as a way to increase more the scores of the different models and the flexibility of the system that has been proposes in education and work environments."
    }
}