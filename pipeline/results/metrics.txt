=== deepseekv2 ===
ideas_total=39, judge_scored=39
novelty_col=biblio_novelty_seed, Spearman(judge, biblio_novelty_seed) = 0.060
Mean judge overall = 3.767 [3.637,3.896]
Mean biblio_novelty_seed = 0.369 [0.334,0.408]
Verdicts: {'revise': 32, 'reject': 5, 'accept': 2}

=== deepseekv3 ===
ideas_total=53, judge_scored=53
novelty_col=biblio_novelty_seed, Spearman(judge, biblio_novelty_seed) = 0.086
Mean judge overall = 4.029 [3.939,4.117]
Mean biblio_novelty_seed = 0.334 [0.305,0.365]
Verdicts: {'revise': 34, 'accept': 18, 'reject': 1}

=== llama3.1 ===
ideas_total=46, judge_scored=46
novelty_col=biblio_novelty_seed, Spearman(judge, biblio_novelty_seed) = -0.159
Mean judge overall = 3.676 [3.550,3.804]
Mean biblio_novelty_seed = 0.357 [0.324,0.389]
Verdicts: {'revise': 36, 'reject': 7, 'accept': 3}
